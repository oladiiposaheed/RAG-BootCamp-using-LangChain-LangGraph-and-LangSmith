{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be3df10b",
   "metadata": {},
   "source": [
    "Building RAG System with LangChain and ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "822511c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "e41c21cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import langchain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Import vectorstore\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c628c8",
   "metadata": {},
   "source": [
    "1. Create Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "e5cfbf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# Define a list of documents, each as a separate string\n",
    "docs = [\n",
    "    '''\n",
    "    Python Programming Language\n",
    "    \n",
    "    üêç **Python** is a high-level, interpreted programming language known for its simplicity and readability.  \n",
    "    üí° It supports multiple programming paradigms, including procedural, object-oriented, and functional styles.  \n",
    "    üöÄ Widely used in web development, data science, automation, AI, and more.  \n",
    "    üìö Python has a vast ecosystem of libraries and frameworks like Django, NumPy, and TensorFlow.  \n",
    "    üåç Its clear syntax and strong community make it ideal for beginners and professionals alike.\n",
    "    ''',\n",
    "\n",
    "    '''\n",
    "    Introduction to Machine Learning\n",
    "    \n",
    "    ü§ñ **Machine Learning (ML)** is a branch of artificial intelligence that enables systems to learn from data without being explicitly programmed.  \n",
    "    üìà It uses algorithms to identify patterns, make predictions, or improve performance over time.  \n",
    "    üß† ML models are trained on datasets and adjust themselves based on feedback or new inputs.  \n",
    "    üîç Common types include supervised, unsupervised, and reinforcement learning.  \n",
    "    üí¨ Applications range from speech recognition and spam filtering to fraud detection and self-driving cars.  \n",
    "    üõ†Ô∏è Tools like Python, TensorFlow, and Scikit-learn are popular in ML development.  \n",
    "    üåç ML is transforming industries by automating decisions and uncovering insights from big data.\n",
    "    ''',\n",
    "\n",
    "    '''\n",
    "    Django for Backend Development\n",
    "    \n",
    "    üåê **Django** is a high-level Python web framework that enables rapid development of secure and maintainable websites.  \n",
    "    ‚öôÔ∏è It follows the Model-View-Template (MVT) architectural pattern to separate data, logic, and presentation.  \n",
    "    üöÄ Django comes with built-in features like authentication, admin interface, and URL routing.  \n",
    "    üõ°Ô∏è It emphasizes security, helping developers avoid common threats like SQL injection and cross-site scripting.  \n",
    "    üì¶ With its \"batteries-included\" philosophy, Django provides everything needed to build full-stack web apps.  \n",
    "    üîç It's widely used for content management systems, social networks, and scientific platforms.  \n",
    "    üåç Django powers popular sites like Instagram, Pinterest, and Mozilla.\n",
    "    ''',\n",
    "\n",
    "    '''\n",
    "    Introduction to Deep Learning\n",
    "    \n",
    "    üß† **Deep Learning** is a subset of machine learning that uses neural networks with many layers to model complex patterns in data.  \n",
    "    üîó These layers mimic the human brain‚Äôs structure, enabling systems to learn hierarchical representations.  \n",
    "    üìö It excels at tasks like image recognition, natural language processing, and speech translation.  \n",
    "    üß™ Deep learning models require large datasets and powerful computing resources to train effectively.  \n",
    "    üï∏Ô∏è Popular architectures include Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs).  \n",
    "    üõ†Ô∏è Frameworks like TensorFlow and PyTorch are commonly used to build deep learning applications.  \n",
    "    üöÄ Deep learning drives innovations in autonomous vehicles, medical diagnostics, and generative AI.\n",
    "    '''\n",
    "]\n",
    "\n",
    "# Verify how many documents are in the list\n",
    "print(len(docs))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "0fd3d21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents created in: C:\\Users\\USER\\AppData\\Local\\Temp\\tmphm8n99hy\n"
     ]
    }
   ],
   "source": [
    "# Save sample documents to files\n",
    "import tempfile\n",
    "\n",
    "files_dir = tempfile.mkdtemp()\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    with open(f'{files_dir}/doc_{i+1}.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(doc)\n",
    "\n",
    "print(f'Documents created in: {files_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "b9cb84db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents created in: C:\\Users\\USER\\AppData\\Local\\Temp\\tmp959ppbhd\n"
     ]
    }
   ],
   "source": [
    "# Save sample documents to files\n",
    "import tempfile\n",
    "\n",
    "files_dir = tempfile.mkdtemp()\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    with open(f'doc_{i+1}.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(doc)\n",
    "\n",
    "print(f'Documents created in: {files_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9a349d",
   "metadata": {},
   "source": [
    "2. Load Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "eb70b1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 documents\n",
      "\n",
      "First document preview:\n",
      "\n",
      "    Python Programming Language\n",
      "\n",
      "    üêç **Python** is a high-level, interpreted programming language known for its simplicity and readability.  \n",
      "    üí° It supports multiple programming paradigms, including procedural, object-oriented, and functional styles.  \n",
      "    üöÄ Widely used in web development, data science, automation, AI, and more.  \n",
      "    üìö Python has a vast ecosystem of libraries and frameworks like Django, NumPy, and TensorFlow.  \n",
      "    üåç Its clear syntax and strong community make it ideal for beginners and professionals alike.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "# Load documents from directory\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    'data',\n",
    "    glob='*.txt',\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={'encoding': 'utf-8'}\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "print(f'Loaded {len(documents)} documents')\n",
    "print(f'\\nFirst document preview:')\n",
    "print(documents[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "611befa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='\\n    Python Programming Language\\n\\n    üêç **Python** is a high-level, interpreted programming language known for its simplicity and readability.  \\n    üí° It supports multiple programming paradigms, including procedural, object-oriented, and functional styles.  \\n    üöÄ Widely used in web development, data science, automation, AI, and more.  \\n    üìö Python has a vast ecosystem of libraries and frameworks like Django, NumPy, and TensorFlow.  \\n    üåç Its clear syntax and strong community make it ideal for beginners and professionals alike.\\n    '),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='\\n    Introduction to Machine Learning\\n\\n    ü§ñ **Machine Learning (ML)** is a branch of artificial intelligence that enables systems to learn from data without being explicitly programmed.  \\n    üìà It uses algorithms to identify patterns, make predictions, or improve performance over time.  \\n    üß† ML models are trained on datasets and adjust themselves based on feedback or new inputs.  \\n    üîç Common types include supervised, unsupervised, and reinforcement learning.  \\n    üí¨ Applications range from speech recognition and spam filtering to fraud detection and self-driving cars.  \\n    üõ†Ô∏è Tools like Python, TensorFlow, and Scikit-learn are popular in ML development.  \\n    üåç ML is transforming industries by automating decisions and uncovering insights from big data.\\n    '),\n",
       " Document(metadata={'source': 'data\\\\doc_3.txt'}, page_content='\\n    Django for Backend Development\\n\\n    üåê **Django** is a high-level Python web framework that enables rapid development of secure and maintainable websites.  \\n    ‚öôÔ∏è It follows the Model-View-Template (MVT) architectural pattern to separate data, logic, and presentation.  \\n    üöÄ Django comes with built-in features like authentication, admin interface, and URL routing.  \\n    üõ°Ô∏è It emphasizes security, helping developers avoid common threats like SQL injection and cross-site scripting.  \\n    üì¶ With its \"batteries-included\" philosophy, Django provides everything needed to build full-stack web apps.  \\n    üîç It\\'s widely used for content management systems, social networks, and scientific platforms.  \\n    üåç Django powers popular sites like Instagram, Pinterest, and Mozilla.\\n    '),\n",
       " Document(metadata={'source': 'data\\\\doc_4.txt'}, page_content='\\n    Introduction to Deep Learning\\n\\n    üß† **Deep Learning** is a subset of machine learning that uses neural networks with many layers to model complex patterns in data.  \\n    üîó These layers mimic the human brain‚Äôs structure, enabling systems to learn hierarchical representations.  \\n    üìö It excels at tasks like image recognition, natural language processing, and speech translation.  \\n    üß™ Deep learning models require large datasets and powerful computing resources to train effectively.  \\n    üï∏Ô∏è Popular architectures include Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs).  \\n    üõ†Ô∏è Frameworks like TensorFlow and PyTorch are commonly used to build deep learning applications.  \\n    üöÄ Deep learning drives innovations in autonomous vehicles, medical diagnostics, and generative AI.\\n    ')]"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a7ad84",
   "metadata": {},
   "source": [
    "3. Splitting Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "3f4eb9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Python Programming Language'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='üêç **Python** is a high-level, interpreted programming language known for its simplicity and readability.  \\n    üí° It supports multiple programming paradigms, including procedural, object-oriented, and functional styles.  \\n    üöÄ Widely used in web development, data science, automation, AI, and more.  \\n    üìö Python has a vast ecosystem of libraries and frameworks like Django, NumPy, and TensorFlow.'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='üåç Its clear syntax and strong community make it ideal for beginners and professionals alike.'),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Introduction to Machine Learning'),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='ü§ñ **Machine Learning (ML)** is a branch of artificial intelligence that enables systems to learn from data without being explicitly programmed.  \\n    üìà It uses algorithms to identify patterns, make predictions, or improve performance over time.  \\n    üß† ML models are trained on datasets and adjust themselves based on feedback or new inputs.  \\n    üîç Common types include supervised, unsupervised, and reinforcement learning.'),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='üí¨ Applications range from speech recognition and spam filtering to fraud detection and self-driving cars.  \\n    üõ†Ô∏è Tools like Python, TensorFlow, and Scikit-learn are popular in ML development.  \\n    üåç ML is transforming industries by automating decisions and uncovering insights from big data.'),\n",
       " Document(metadata={'source': 'data\\\\doc_3.txt'}, page_content='Django for Backend Development'),\n",
       " Document(metadata={'source': 'data\\\\doc_3.txt'}, page_content='üåê **Django** is a high-level Python web framework that enables rapid development of secure and maintainable websites.  \\n    ‚öôÔ∏è It follows the Model-View-Template (MVT) architectural pattern to separate data, logic, and presentation.  \\n    üöÄ Django comes with built-in features like authentication, admin interface, and URL routing.  \\n    üõ°Ô∏è It emphasizes security, helping developers avoid common threats like SQL injection and cross-site scripting.'),\n",
       " Document(metadata={'source': 'data\\\\doc_3.txt'}, page_content='üì¶ With its \"batteries-included\" philosophy, Django provides everything needed to build full-stack web apps.  \\n    üîç It\\'s widely used for content management systems, social networks, and scientific platforms.  \\n    üåç Django powers popular sites like Instagram, Pinterest, and Mozilla.'),\n",
       " Document(metadata={'source': 'data\\\\doc_4.txt'}, page_content='Introduction to Deep Learning'),\n",
       " Document(metadata={'source': 'data\\\\doc_4.txt'}, page_content='üß† **Deep Learning** is a subset of machine learning that uses neural networks with many layers to model complex patterns in data.  \\n    üîó These layers mimic the human brain‚Äôs structure, enabling systems to learn hierarchical representations.  \\n    üìö It excels at tasks like image recognition, natural language processing, and speech translation.  \\n    üß™ Deep learning models require large datasets and powerful computing resources to train effectively.'),\n",
       " Document(metadata={'source': 'data\\\\doc_4.txt'}, page_content='üï∏Ô∏è Popular architectures include Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs).  \\n    üõ†Ô∏è Frameworks like TensorFlow and PyTorch are commonly used to build deep learning applications.  \\n    üöÄ Deep learning drives innovations in autonomous vehicles, medical diagnostics, and generative AI.')]"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize text splitter\n",
    "test_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,          # chunk size for balanced context\n",
    "    chunk_overlap=50,        # overlap to maintain continuity between chunks\n",
    "    length_function=len,     # function used to measure chunk length in characters\n",
    "    separators=['\\n\\n', '\\n', '. ', ' ', '']   # clean text‚Äësplitting order\n",
    ")\n",
    "\n",
    "chunks = test_splitter.split_documents(documents)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "a3915f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks\n",
      "Content: Python Programming Language\n",
      "Metadata: {'source': 'data\\\\doc_1.txt'}\n"
     ]
    }
   ],
   "source": [
    "print('Chunks')\n",
    "print(f'Content: {chunks[0].page_content}')\n",
    "print(f'Metadata: {chunks[0].metadata}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13f85e6",
   "metadata": {},
   "source": [
    "4. Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "48ae332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OPENAI_API_KEY\n",
    "openai_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "f7e5625f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x000002688EA0BA00>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x000002688EA0B790>, model='text-embedding-ada-002', dimensions=None, deployment='text-embedding-ada-002', openai_api_version=None, openai_api_base=None, openai_api_type=None, openai_proxy=None, embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True)"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'LangChain makes it easy to use LLMs.'\n",
    "embeddings = OpenAIEmbeddings()\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "47935764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.006602696608752012,\n",
       " 0.021901967003941536,\n",
       " -0.03336246311664581,\n",
       " -0.04902467131614685,\n",
       " 0.0063758594915270805,\n",
       " 0.009234003722667694,\n",
       " -0.02099462039768696,\n",
       " -0.004065613728016615,\n",
       " -0.005562737118452787,\n",
       " -0.016569558531045914,\n",
       " 0.0004052527074236423,\n",
       " -0.0028127767145633698,\n",
       " -0.0032298073638230562,\n",
       " 0.019947681576013565,\n",
       " 0.010567106306552887,\n",
       " 0.024149397388100624,\n",
       " 0.016681231558322906,\n",
       " 0.0037271035835146904,\n",
       " 0.012074698694050312,\n",
       " 0.0042296345345675945,\n",
       " -0.022683681920170784,\n",
       " -0.019794130697846413,\n",
       " -0.0010809646919369698,\n",
       " -0.0335858091711998,\n",
       " -0.0031757154501974583,\n",
       " 0.011956045404076576,\n",
       " 0.03626597300171852,\n",
       " -0.02025478333234787,\n",
       " -0.03741062805056572,\n",
       " 0.0025074193254113197,\n",
       " 0.013142576441168785,\n",
       " 0.008256860077381134,\n",
       " -0.027862541377544403,\n",
       " -0.014336087740957737,\n",
       " -0.013603230006992817,\n",
       " -0.003988838288933039,\n",
       " 0.021343600004911423,\n",
       " 0.0011559954145923257,\n",
       " 0.02042229473590851,\n",
       " 0.0020275721326470375,\n",
       " 0.02518237754702568,\n",
       " 0.009876126423478127,\n",
       " 0.002838950138539076,\n",
       " -0.011963024735450745,\n",
       " -0.0013505516108125448,\n",
       " 0.001517189433798194,\n",
       " 0.02290702983736992,\n",
       " -0.011586126871407032,\n",
       " -0.04246385395526886,\n",
       " -0.012779638171195984,\n",
       " -0.0010181483812630177,\n",
       " 0.026955194771289825,\n",
       " -0.028546541929244995,\n",
       " 0.004456471186131239,\n",
       " -0.015578455291688442,\n",
       " 2.6187111870967783e-05,\n",
       " 0.016318291425704956,\n",
       " -0.0003446174960117787,\n",
       " 0.029844745993614197,\n",
       " -0.02106441743671894,\n",
       " -0.010169269517064095,\n",
       " -0.009931962937116623,\n",
       " -0.020771274343132973,\n",
       " -0.004459960851818323,\n",
       " 0.015718046575784683,\n",
       " -0.009687677025794983,\n",
       " 0.0022509193513542414,\n",
       " 0.03752230107784271,\n",
       " 0.013917312026023865,\n",
       " -0.007147104945033789,\n",
       " 0.0033345012925565243,\n",
       " -0.01601118966937065,\n",
       " -0.003967899363487959,\n",
       " -0.008954820223152637,\n",
       " 0.001511082286015153,\n",
       " -0.01601118966937065,\n",
       " -0.0036922055296599865,\n",
       " -0.01936139538884163,\n",
       " -0.014105760492384434,\n",
       " 0.00021854855003766716,\n",
       " 0.01147445384413004,\n",
       " -0.0019124089740216732,\n",
       " 0.00042815451161004603,\n",
       " 0.04318973049521446,\n",
       " 0.03299952298402786,\n",
       " -0.004788001999258995,\n",
       " 0.010071555152535439,\n",
       " 0.0012292810715734959,\n",
       " -0.01781192608177662,\n",
       " -0.026257235556840897,\n",
       " 0.0024934601970016956,\n",
       " 0.008382492698729038,\n",
       " 0.017295435070991516,\n",
       " -0.004972961265593767,\n",
       " -0.019207844510674477,\n",
       " -0.0020537457894533873,\n",
       " 0.0002730766427703202,\n",
       " 0.0026173479855060577,\n",
       " -0.007258778437972069,\n",
       " -0.015145719982683659,\n",
       " -0.014189516194164753,\n",
       " 0.006588737480342388,\n",
       " 0.009499228559434414,\n",
       " -0.009722575545310974,\n",
       " -0.015913475304841995,\n",
       " -0.03911364823579788,\n",
       " 0.014699026010930538,\n",
       " 0.005395226646214724,\n",
       " 0.024219192564487457,\n",
       " 0.013219351880252361,\n",
       " -0.026550378650426865,\n",
       " 0.029370134696364403,\n",
       " -0.006456125061959028,\n",
       " -0.005782593972980976,\n",
       " 0.0005483343848027289,\n",
       " -0.017016252502799034,\n",
       " 0.017253557220101357,\n",
       " -0.023814376443624496,\n",
       " 0.015787843614816666,\n",
       " -0.01609494537115097,\n",
       " 0.031184827908873558,\n",
       " 0.01114641223102808,\n",
       " 0.034451279789209366,\n",
       " -0.007140125147998333,\n",
       " 0.013931270688772202,\n",
       " 0.026480581611394882,\n",
       " -0.020715435966849327,\n",
       " -0.012744739651679993,\n",
       " -0.024149397388100624,\n",
       " -0.009059513919055462,\n",
       " 0.018998457118868828,\n",
       " 0.014084821566939354,\n",
       " 0.008305717259645462,\n",
       " 0.01703021116554737,\n",
       " -0.0070947580970823765,\n",
       " 0.022851193323731422,\n",
       " 0.018188823014497757,\n",
       " -0.0032490012235939503,\n",
       " -0.020938783884048462,\n",
       " 0.01569012925028801,\n",
       " 0.017923599109053612,\n",
       " 0.03138025850057602,\n",
       " 0.008221962489187717,\n",
       " 0.005587165709584951,\n",
       " -0.0005827961722388864,\n",
       " 0.022767437621951103,\n",
       " -0.0020415314938873053,\n",
       " -0.00595010444521904,\n",
       " 0.002774388762190938,\n",
       " -0.02571282722055912,\n",
       " -0.0018565721111372113,\n",
       " -0.005074165295809507,\n",
       " -0.005562737118452787,\n",
       " -0.0017483884003013372,\n",
       " 0.009136289358139038,\n",
       " 0.023214131593704224,\n",
       " 0.027764827013015747,\n",
       " 0.033837076276540756,\n",
       " -0.03679642453789711,\n",
       " -0.0065084719099104404,\n",
       " -0.02779274620115757,\n",
       " 0.030207686126232147,\n",
       " 0.0038981034886091948,\n",
       " 0.0024323887191712856,\n",
       " 0.022474294528365135,\n",
       " 0.028783848509192467,\n",
       " 0.012982046231627464,\n",
       " -0.008815228007733822,\n",
       " -0.0035194605588912964,\n",
       " 0.01230502501130104,\n",
       " -0.0012266637058928609,\n",
       " 0.027401888743042946,\n",
       " -0.04447397589683533,\n",
       " 0.012891311198472977,\n",
       " -0.025489479303359985,\n",
       " 0.005363818258047104,\n",
       " 0.02399584650993347,\n",
       " -0.009185146540403366,\n",
       " -0.011111514642834663,\n",
       " -0.01845404878258705,\n",
       " 0.00953412614762783,\n",
       " -0.004030715674161911,\n",
       " 0.005506900139153004,\n",
       " 0.02950972691178322,\n",
       " -0.053854551166296005,\n",
       " -0.0056988392025232315,\n",
       " -0.006243247538805008,\n",
       " -0.008466248400509357,\n",
       " 0.0036712668370455503,\n",
       " -0.01744898594915867,\n",
       " -0.0009701636736281216,\n",
       " 0.012179392389953136,\n",
       " 0.008508126251399517,\n",
       " -0.024135438725352287,\n",
       " -0.6530666947364807,\n",
       " -0.018440088257193565,\n",
       " 0.00931077916175127,\n",
       " -0.020366456359624863,\n",
       " 0.013128617778420448,\n",
       " -0.005496430676430464,\n",
       " 0.004316879436373711,\n",
       " 0.006976104807108641,\n",
       " -0.028016092255711555,\n",
       " 0.01989184506237507,\n",
       " -0.004365736618638039,\n",
       " -0.003034378867596388,\n",
       " 0.013016943819820881,\n",
       " -0.004927593749016523,\n",
       " -0.018523843958973885,\n",
       " -0.018886782228946686,\n",
       " -0.006145533174276352,\n",
       " -0.03489797189831734,\n",
       " 0.005925675854086876,\n",
       " 0.018998457118868828,\n",
       " -0.005548777524381876,\n",
       " 0.0004072157316841185,\n",
       " -0.01613682322204113,\n",
       " 0.002779623493552208,\n",
       " -0.012277106754481792,\n",
       " -0.0012580719776451588,\n",
       " 0.028169643133878708,\n",
       " -0.004124940373003483,\n",
       " -0.0005740716587752104,\n",
       " 0.015215516090393066,\n",
       " -0.032496992498636246,\n",
       " 0.005458042956888676,\n",
       " -0.008703554049134254,\n",
       " -0.005213757045567036,\n",
       " 0.03858320042490959,\n",
       " -0.000802217167802155,\n",
       " -0.03280409425497055,\n",
       " 0.012011881917715073,\n",
       " 0.002945388900116086,\n",
       " 0.017169803380966187,\n",
       " -0.04352475330233574,\n",
       " -0.02000351808965206,\n",
       " 0.013603230006992817,\n",
       " 0.017002291977405548,\n",
       " -0.011495392769575119,\n",
       " 0.010057595558464527,\n",
       " 0.03339038044214249,\n",
       " 0.01601118966937065,\n",
       " 0.004798471461981535,\n",
       " -0.015704087913036346,\n",
       " 0.004226144403219223,\n",
       " -0.023297887295484543,\n",
       " 0.004240103531628847,\n",
       " 0.0163741298019886,\n",
       " 0.007482125423848629,\n",
       " -0.002533592749387026,\n",
       " 0.03246907517313957,\n",
       " -0.002978541888296604,\n",
       " 0.011334861628711224,\n",
       " 0.017993394285440445,\n",
       " -0.010874208062887192,\n",
       " 0.015327190048992634,\n",
       " -0.03972785174846649,\n",
       " -0.011767596937716007,\n",
       " -0.0051614101976156235,\n",
       " -0.0056011248379945755,\n",
       " -0.018607599660754204,\n",
       " 0.00019531958969309926,\n",
       " 0.01842612959444523,\n",
       " -0.005520859267562628,\n",
       " 0.022976825013756752,\n",
       " 0.02367478422820568,\n",
       " 0.004903165157884359,\n",
       " -0.0018286537379026413,\n",
       " -0.009185146540403366,\n",
       " 0.012514413334429264,\n",
       " 0.01874719187617302,\n",
       " 0.009813309647142887,\n",
       " -0.015327190048992634,\n",
       " 0.025280091911554337,\n",
       " 0.004910144954919815,\n",
       " -0.020520007237792015,\n",
       " -0.009617880918085575,\n",
       " -0.015480740927159786,\n",
       " 0.02567094936966896,\n",
       " 0.021915927529335022,\n",
       " -0.005377777852118015,\n",
       " -0.04193340614438057,\n",
       " 0.001452628173865378,\n",
       " 0.01192114781588316,\n",
       " 0.010574085637927055,\n",
       " 0.021901967003941536,\n",
       " -0.029146786779165268,\n",
       " -0.04092834144830704,\n",
       " 0.0059396349824965,\n",
       " 0.03006809391081333,\n",
       " 0.0038562261033803225,\n",
       " 0.04690287634730339,\n",
       " 0.011488412506878376,\n",
       " -0.0369080975651741,\n",
       " -0.009652779437601566,\n",
       " 0.0023416539188474417,\n",
       " -0.003974879160523415,\n",
       " -0.006857451517134905,\n",
       " 0.012270127423107624,\n",
       " 0.01118829008191824,\n",
       " 0.000653028313536197,\n",
       " -0.005820981692522764,\n",
       " 0.03858320042490959,\n",
       " 0.0004170307656750083,\n",
       " -0.004030715674161911,\n",
       " -0.00018615886801853776,\n",
       " -0.00880126841366291,\n",
       " -0.001497995457611978,\n",
       " -0.026843521744012833,\n",
       " -0.03509340062737465,\n",
       " -0.0024114500265568495,\n",
       " 0.0046728383749723434,\n",
       " 0.023535193875432014,\n",
       " -0.03556801378726959,\n",
       " -0.0018722763052210212,\n",
       " 0.005761655513197184,\n",
       " 0.01588555797934532,\n",
       " 0.008473227731883526,\n",
       " -0.005328920669853687,\n",
       " 0.015243434347212315,\n",
       " 0.0063374717719852924,\n",
       " -0.005932655651122332,\n",
       " -0.0017719445750117302,\n",
       " 0.012228249572217464,\n",
       " -0.01120922900736332,\n",
       " -0.0067667169496417046,\n",
       " 0.028351113200187683,\n",
       " -0.01116735115647316,\n",
       " 0.026829561218619347,\n",
       " 0.030961481854319572,\n",
       " 0.04023038223385811,\n",
       " 0.001456990372389555,\n",
       " 0.004655389580875635,\n",
       " -0.0019106640247628093,\n",
       " 0.018970537930727005,\n",
       " 0.010197187773883343,\n",
       " -0.0038038790225982666,\n",
       " -0.0243308674544096,\n",
       " -0.03838777169585228,\n",
       " -0.03185487166047096,\n",
       " -0.0228232741355896,\n",
       " 0.030877726152539253,\n",
       " -0.011425596661865711,\n",
       " -0.0071680438704788685,\n",
       " -0.009589962661266327,\n",
       " -0.011711759492754936,\n",
       " -0.03433960676193237,\n",
       " 0.02074335515499115,\n",
       " -0.009052534587681293,\n",
       " -0.02119004912674427,\n",
       " -0.005702328868210316,\n",
       " -0.013666045852005482,\n",
       " -0.0063619003631174564,\n",
       " -0.03464670851826668,\n",
       " 0.027932338416576385,\n",
       " -0.00037864301702938974,\n",
       " -0.025866378098726273,\n",
       " 0.000735038542188704,\n",
       " 0.022195110097527504,\n",
       " 0.0023591029457747936,\n",
       " 0.03157568722963333,\n",
       " 0.0033484604209661484,\n",
       " -0.00042815451161004603,\n",
       " -0.014077842235565186,\n",
       " -0.023828335106372833,\n",
       " -0.01796547695994377,\n",
       " -0.02192988619208336,\n",
       " 0.0123469028621912,\n",
       " 0.015578455291688442,\n",
       " 0.007405349984765053,\n",
       " 0.012235228903591633,\n",
       " -0.01485257688909769,\n",
       " 0.0036433483473956585,\n",
       " -0.0010024443035945296,\n",
       " -0.0008816100307740271,\n",
       " 0.03810858726501465,\n",
       " -0.012256167829036713,\n",
       " -0.013854495249688625,\n",
       " 0.03939283266663551,\n",
       " 0.005091614089906216,\n",
       " 0.001540745492093265,\n",
       " 0.02065959945321083,\n",
       " 0.004435532260686159,\n",
       " 0.01577388308942318,\n",
       " 0.010950983501970768,\n",
       " 0.029816828668117523,\n",
       " -0.009052534587681293,\n",
       " -0.017714211717247963,\n",
       " 0.0024760111700743437,\n",
       " 0.007733390666544437,\n",
       " -0.004997389856725931,\n",
       " -5.024762867833488e-05,\n",
       " 0.0361822172999382,\n",
       " 0.0034566442482173443,\n",
       " -0.008473227731883526,\n",
       " -0.007914860732853413,\n",
       " 0.010385637171566486,\n",
       " -0.035400502383708954,\n",
       " -0.0013078015763312578,\n",
       " -0.028839685022830963,\n",
       " -0.004508818034082651,\n",
       " -0.014824658632278442,\n",
       " 0.009722575545310974,\n",
       " 0.020966703072190285,\n",
       " -0.015257393941283226,\n",
       " -0.0034252360928803682,\n",
       " -0.004878736566752195,\n",
       " -0.004854307975620031,\n",
       " 0.008228941820561886,\n",
       " 0.028379032388329506,\n",
       " -0.006920267827808857,\n",
       " 0.007004023063927889,\n",
       " 0.00908743217587471,\n",
       " -0.002749960171058774,\n",
       " 0.011111514642834663,\n",
       " -0.024959029629826546,\n",
       " 0.018105069175362587,\n",
       " -0.0071680438704788685,\n",
       " 0.007558900862932205,\n",
       " 0.0007127911085262895,\n",
       " -0.007810166571289301,\n",
       " 0.010148330591619015,\n",
       " -0.031184827908873558,\n",
       " -0.014056903310120106,\n",
       " -0.011153392493724823,\n",
       " 0.004676328506320715,\n",
       " -0.003050082828849554,\n",
       " 0.010211147367954254,\n",
       " 0.008501145988702774,\n",
       " 0.001297332113608718,\n",
       " 0.019738294184207916,\n",
       " -0.0012345158029347658,\n",
       " 0.017797965556383133,\n",
       " -0.0011961280833929777,\n",
       " -0.00025104728410951793,\n",
       " 0.006257206667214632,\n",
       " 0.016764985397458076,\n",
       " 0.00618392089381814,\n",
       " 0.03366956487298012,\n",
       " 0.03138025850057602,\n",
       " 0.025377806276082993,\n",
       " 0.005077654961496592,\n",
       " -0.0038352871779352427,\n",
       " -0.028099847957491875,\n",
       " -0.02742980606853962,\n",
       " 0.026871439069509506,\n",
       " -0.00536032859236002,\n",
       " 0.006190900225192308,\n",
       " 0.015313230454921722,\n",
       " -0.0068016150034964085,\n",
       " 0.019445151090621948,\n",
       " 0.012633066624403,\n",
       " 0.01793755777180195,\n",
       " 0.01515967957675457,\n",
       " -0.009492248296737671,\n",
       " 0.007593798916786909,\n",
       " -0.0038771647959947586,\n",
       " 0.001978715183213353,\n",
       " 0.017169803380966187,\n",
       " -0.013561352156102657,\n",
       " 0.0023678275756537914,\n",
       " -0.01026698388159275,\n",
       " -0.0031390725634992123,\n",
       " -0.009666738100349903,\n",
       " 0.02399584650993347,\n",
       " 0.013889392837882042,\n",
       " 0.009645800106227398,\n",
       " -0.02294890768826008,\n",
       " 0.009673718363046646,\n",
       " -0.01906825229525566,\n",
       " 0.010308860801160336,\n",
       " 0.005123022478073835,\n",
       " 0.007859023287892342,\n",
       " 0.011690820567309856,\n",
       " -0.01092306524515152,\n",
       " -0.01976621150970459,\n",
       " 0.028574461117386818,\n",
       " 0.001648056786507368,\n",
       " -0.02452629618346691,\n",
       " -0.0324411541223526,\n",
       " -0.025503437966108322,\n",
       " 0.020268741995096207,\n",
       " 0.012730780988931656,\n",
       " 0.0021636742167174816,\n",
       " 0.017700251191854477,\n",
       " -0.0027517052367329597,\n",
       " 0.013638127595186234,\n",
       " 0.004484389442950487,\n",
       " -0.007042410783469677,\n",
       " 0.008878044784069061,\n",
       " 0.028295276686549187,\n",
       " -0.01972433365881443,\n",
       " -0.016471844166517258,\n",
       " -0.011760616675019264,\n",
       " 0.005810512695461512,\n",
       " 0.01940327323973179,\n",
       " 0.0006294721970334649,\n",
       " -0.022278865799307823,\n",
       " 0.0437760166823864,\n",
       " -0.0038771647959947586,\n",
       " -0.039588261395692825,\n",
       " 0.00030688405968248844,\n",
       " 0.007342533674091101,\n",
       " 0.005196308251470327,\n",
       " 0.007977676577866077,\n",
       " -0.011669882573187351,\n",
       " -0.005800043232738972,\n",
       " -0.017393149435520172,\n",
       " 0.03140817582607269,\n",
       " 0.011355800554156303,\n",
       " 0.00641773734241724,\n",
       " 0.00859886035323143,\n",
       " 0.02730417437851429,\n",
       " -0.009673718363046646,\n",
       " -0.004596062935888767,\n",
       " -0.023423518985509872,\n",
       " -0.031268585473299026,\n",
       " 0.013428740203380585,\n",
       " 0.045004427433013916,\n",
       " 0.010657841339707375,\n",
       " 0.004934573546051979,\n",
       " 0.015215516090393066,\n",
       " -0.03104523755609989,\n",
       " -0.014154617674648762,\n",
       " -0.008340615779161453,\n",
       " -0.039755769073963165,\n",
       " 0.008040493354201317,\n",
       " 0.014322128146886826,\n",
       " -0.011069636791944504,\n",
       " -0.01515967957675457,\n",
       " 0.0034496646840125322,\n",
       " 0.005824471823871136,\n",
       " 0.034255851060152054,\n",
       " 0.012193351984024048,\n",
       " -0.01053220871835947,\n",
       " -0.01694645546376705,\n",
       " -0.01285641361027956,\n",
       " -0.0037759607657790184,\n",
       " 0.019542865455150604,\n",
       " -0.003123368602246046,\n",
       " 0.012772657908499241,\n",
       " 0.00912931002676487,\n",
       " -0.0033973176032304764,\n",
       " 0.015075924806296825,\n",
       " 0.020394375547766685,\n",
       " 0.01609494537115097,\n",
       " -0.00571628799661994,\n",
       " -0.01972433365881443,\n",
       " 0.02322809025645256,\n",
       " 2.0393503291415982e-05,\n",
       " 0.02220907062292099,\n",
       " 0.021217968314886093,\n",
       " -0.01489445473998785,\n",
       " 0.03260866552591324,\n",
       " -0.031073154881596565,\n",
       " -0.012626086361706257,\n",
       " 0.0297889094799757,\n",
       " -0.009834248572587967,\n",
       " 0.009589962661266327,\n",
       " 0.01645788364112377,\n",
       " 0.009213064797222614,\n",
       " 0.014049923978745937,\n",
       " 0.007293676491826773,\n",
       " -0.00998779945075512,\n",
       " -0.011013800278306007,\n",
       " 0.023256009444594383,\n",
       " 0.0019281130516901612,\n",
       " 0.004362246487289667,\n",
       " 0.01485257688909769,\n",
       " -0.0026103684213012457,\n",
       " -0.036377646028995514,\n",
       " -0.015187597833573818,\n",
       " 0.008424370549619198,\n",
       " 0.009171186946332455,\n",
       " -0.012130535207688808,\n",
       " 0.015466781333088875,\n",
       " -0.0010373422410339117,\n",
       " -0.020589804276823997,\n",
       " -0.02004539594054222,\n",
       " -0.016513720154762268,\n",
       " -0.005786084104329348,\n",
       " -0.010364698246121407,\n",
       " -0.007551921531558037,\n",
       " -0.0033275217283517122,\n",
       " -0.03883446380496025,\n",
       " 0.004564655013382435,\n",
       " -0.01560637354850769,\n",
       " -0.00977841205894947,\n",
       " -0.029118869453668594,\n",
       " -0.0069237579591572285,\n",
       " -0.030458951368927956,\n",
       " 0.004986920394003391,\n",
       " 0.0037061646580696106,\n",
       " 0.005541798193007708,\n",
       " 0.027890460565686226,\n",
       " 0.010357717983424664,\n",
       " 0.016360169276595116,\n",
       " 0.02579658105969429,\n",
       " -0.0048333690501749516,\n",
       " 0.019054293632507324,\n",
       " -0.014740903861820698,\n",
       " -0.01373584195971489,\n",
       " -0.0233956016600132,\n",
       " 0.0077473497949540615,\n",
       " 0.0018321436364203691,\n",
       " -0.00044080501538701355,\n",
       " -0.00886408518999815,\n",
       " -0.005395226646214724,\n",
       " 0.005475491750985384,\n",
       " -8.266457007266581e-05,\n",
       " 0.006574778351932764,\n",
       " -0.013351964764297009,\n",
       " -0.027401888743042946,\n",
       " 0.011572168208658695,\n",
       " 0.042072996497154236,\n",
       " 0.027164582163095474,\n",
       " -0.008850125595927238,\n",
       " -0.011425596661865711,\n",
       " 0.0036991850938647985,\n",
       " -0.024386703968048096,\n",
       " -0.0022125313989818096,\n",
       " 0.004149368964135647,\n",
       " 0.009387554600834846,\n",
       " 0.0009963371558114886,\n",
       " 0.024344826117157936,\n",
       " 0.013652087189257145,\n",
       " -0.013331025838851929,\n",
       " 0.001585240475833416,\n",
       " 0.00019957277982030064,\n",
       " 0.0010216381633654237,\n",
       " 0.0033973176032304764,\n",
       " 0.015438863076269627,\n",
       " 0.01165592297911644,\n",
       " 0.026354949921369553,\n",
       " -0.002907001180574298,\n",
       " -0.010811392217874527,\n",
       " -0.008940860629081726,\n",
       " -0.02872801199555397,\n",
       " -0.014726944267749786,\n",
       " -0.009862166829407215,\n",
       " 0.03554009646177292,\n",
       " 0.013344984501600266,\n",
       " -0.02481943927705288,\n",
       " -0.008543023839592934,\n",
       " 0.024316906929016113,\n",
       " -0.008794289082288742,\n",
       " -0.006700410973280668,\n",
       " 0.01906825229525566,\n",
       " -0.020478131249547005,\n",
       " 0.02681560255587101,\n",
       " -0.0034653686452656984,\n",
       " -0.020799191668629646,\n",
       " -0.024889234453439713,\n",
       " -0.017421068623661995,\n",
       " -0.032832011580467224,\n",
       " 0.001678592525422573,\n",
       " -0.022097395732998848,\n",
       " 0.008892003446817398,\n",
       " -0.0008994952659122646,\n",
       " 0.012633066624403,\n",
       " 0.010930045507848263,\n",
       " -0.023940009996294975,\n",
       " -0.024135438725352287,\n",
       " -0.020226866006851196,\n",
       " -0.029453888535499573,\n",
       " 0.014601311646401882,\n",
       " -0.0037550218403339386,\n",
       " 0.016597475856542587,\n",
       " -0.01645788364112377,\n",
       " 0.008389472961425781,\n",
       " -0.04087250679731369,\n",
       " -0.008012574166059494,\n",
       " 0.014615271240472794,\n",
       " -0.027164582163095474,\n",
       " 0.0008763753576204181,\n",
       " -0.009185146540403366,\n",
       " 0.012172413058578968,\n",
       " 0.013351964764297009,\n",
       " 0.030877726152539253,\n",
       " 0.0007529237773269415,\n",
       " 0.01617870107293129,\n",
       " -0.0049066548235714436,\n",
       " 0.005590655375272036,\n",
       " -0.010783473961055279,\n",
       " 0.019473068416118622,\n",
       " 0.009569024667143822,\n",
       " -0.024358784779906273,\n",
       " 0.009862166829407215,\n",
       " 0.028099847957491875,\n",
       " -0.0038457566406577826,\n",
       " 0.027234377339482307,\n",
       " -0.00928984023630619,\n",
       " 0.008724492974579334,\n",
       " 0.004707736428827047,\n",
       " -0.008159145712852478,\n",
       " 0.004568144679069519,\n",
       " 0.005904736928641796,\n",
       " -0.04380393400788307,\n",
       " 0.0067178597673773766,\n",
       " 0.0024690316058695316,\n",
       " -0.0036189197562634945,\n",
       " -0.011174331419169903,\n",
       " -0.023814376443624496,\n",
       " -0.01257024984806776,\n",
       " -0.0017850312869995832,\n",
       " -0.011711759492754936,\n",
       " 0.025154458358883858,\n",
       " -0.015215516090393066,\n",
       " 0.030654380097985268,\n",
       " 0.006442165933549404,\n",
       " 0.019780172035098076,\n",
       " 0.004889206029474735,\n",
       " 0.009282860904932022,\n",
       " -0.0009474799735471606,\n",
       " -0.004690287634730339,\n",
       " -0.02962139993906021,\n",
       " -0.001757985446602106,\n",
       " 0.007572859991341829,\n",
       " -0.010260003618896008,\n",
       " -0.001287735183723271,\n",
       " -0.0037271035835146904,\n",
       " -0.016848741099238396,\n",
       " 0.02694123610854149,\n",
       " -0.021985722705721855,\n",
       " -0.009450371377170086,\n",
       " 0.0009396279347129166,\n",
       " 0.0017754343571141362,\n",
       " -0.01911013014614582,\n",
       " -0.004592573270201683,\n",
       " -0.04670744761824608,\n",
       " -0.021385477855801582,\n",
       " -0.02286515198647976,\n",
       " 0.009729554876685143,\n",
       " 0.012067719362676144,\n",
       " 0.0019019395112991333,\n",
       " 0.018077149987220764,\n",
       " -0.008242901414632797,\n",
       " -0.009199106134474277,\n",
       " 0.019919762387871742,\n",
       " 0.018105069175362587,\n",
       " 0.01534114871174097,\n",
       " -0.014810699969530106,\n",
       " 0.016639353707432747,\n",
       " -0.0011786790564656258,\n",
       " 0.006609675940126181,\n",
       " -0.026717888191342354,\n",
       " -0.008508126251399517,\n",
       " 0.010748575441539288,\n",
       " -0.019459109753370285,\n",
       " -0.004494858905673027,\n",
       " 0.037019770592451096,\n",
       " 0.008235922083258629,\n",
       " 0.004634450655430555,\n",
       " 0.015075924806296825,\n",
       " 0.011174331419169903,\n",
       " -0.021566947922110558,\n",
       " -0.03752230107784271,\n",
       " -0.00017994266818277538,\n",
       " 0.018858864903450012,\n",
       " 0.024386703968048096,\n",
       " -0.007524002809077501,\n",
       " -0.010804412886500359,\n",
       " 0.004972961265593767,\n",
       " 0.009464330039918423,\n",
       " -0.011669882573187351,\n",
       " 0.02811380662024021,\n",
       " -0.005489451345056295,\n",
       " 0.005681389942765236,\n",
       " -0.0026592256035655737,\n",
       " 0.017351271584630013,\n",
       " -0.0224603358656168,\n",
       " 0.026089724153280258,\n",
       " -0.025782622396945953,\n",
       " 0.0004615256912074983,\n",
       " -0.01883094571530819,\n",
       " -0.023074539378285408,\n",
       " -0.00915024895220995,\n",
       " 0.011502372100949287,\n",
       " 0.012200331315398216,\n",
       " 0.026229316368699074,\n",
       " 0.007080798503011465,\n",
       " 0.010211147367954254,\n",
       " 0.010706698521971703,\n",
       " 0.026229316368699074,\n",
       " -0.011132453568279743,\n",
       " -0.012514413334429264,\n",
       " -0.03112899139523506,\n",
       " 0.026257235556840897,\n",
       " -0.028867604210972786,\n",
       " -0.0007860768237151206,\n",
       " 0.020882947370409966,\n",
       " -0.007789227645844221,\n",
       " 0.022488253191113472,\n",
       " -0.008249880746006966,\n",
       " 0.0037445526104420424,\n",
       " -0.0022055518347769976,\n",
       " -0.008591881021857262,\n",
       " 0.010197187773883343,\n",
       " 0.02322809025645256,\n",
       " -0.007028451655060053,\n",
       " 0.000381478457711637,\n",
       " -0.017504822462797165,\n",
       " -0.009275881573557854,\n",
       " -0.005922186188399792,\n",
       " -0.018970537930727005,\n",
       " -0.019207844510674477,\n",
       " 0.03495381027460098,\n",
       " -0.0445018969476223,\n",
       " 0.01097890269011259,\n",
       " -0.004236613865941763,\n",
       " 0.003946960903704166,\n",
       " -0.012270127423107624,\n",
       " 0.013163515366613865,\n",
       " -0.012647025287151337,\n",
       " -0.0020642150193452835,\n",
       " 0.04101209715008736,\n",
       " -0.03378123790025711,\n",
       " 0.016737068071961403,\n",
       " 0.02539176493883133,\n",
       " -0.001438668929040432,\n",
       " -0.01617870107293129,\n",
       " 0.01240971963852644,\n",
       " 0.015355108305811882,\n",
       " -0.03500964492559433,\n",
       " -0.00014122773427516222,\n",
       " 0.007775268517434597,\n",
       " -0.016416005790233612,\n",
       " -0.01747690513730049,\n",
       " 0.015243434347212315,\n",
       " -0.008214983157813549,\n",
       " 0.023786459118127823,\n",
       " -0.015145719982683659,\n",
       " -0.021525070071220398,\n",
       " 0.003308327868580818,\n",
       " 0.0335858091711998,\n",
       " -0.014615271240472794,\n",
       " -0.006145533174276352,\n",
       " 0.011090575717389584,\n",
       " -0.020282702520489693,\n",
       " 0.005510389804840088,\n",
       " 0.009876126423478127,\n",
       " -0.01577388308942318,\n",
       " -0.0034374503884464502,\n",
       " 0.001355786225758493,\n",
       " -0.017532741650938988,\n",
       " -0.014726944267749786,\n",
       " -0.008263840340077877,\n",
       " -0.015704087913036346,\n",
       " -0.00569534907117486,\n",
       " -0.009897065348923206,\n",
       " 0.010441473685204983,\n",
       " -0.016318291425704956,\n",
       " -0.015466781333088875,\n",
       " -0.010392616502940655,\n",
       " -0.0034985218662768602,\n",
       " 0.009261921979486942,\n",
       " -0.020813150331377983,\n",
       " 0.0048822262324392796,\n",
       " 0.02543364278972149,\n",
       " 0.011551229283213615,\n",
       " 0.020143110305070877,\n",
       " 0.015494699589908123,\n",
       " -0.03777356445789337,\n",
       " -0.012095637619495392,\n",
       " -0.009227024391293526,\n",
       " -0.009876126423478127,\n",
       " -0.0125283719971776,\n",
       " -0.020394375547766685,\n",
       " -0.011830412782728672,\n",
       " 0.041430871933698654,\n",
       " 0.01074159611016512,\n",
       " -0.021497150883078575,\n",
       " -0.025531357154250145,\n",
       " -0.013072780333459377,\n",
       " -0.028267357498407364,\n",
       " 0.004613512195646763,\n",
       " -0.00884314626455307,\n",
       " -0.018858864903450012,\n",
       " -0.00582796148955822,\n",
       " 0.031101074069738388,\n",
       " 0.019263681024312973,\n",
       " 0.04486483335494995,\n",
       " -0.002681909129023552,\n",
       " 0.017295435070991516,\n",
       " -0.0005670920363627374,\n",
       " -0.002022337634116411,\n",
       " -0.004264532122761011,\n",
       " 0.009387554600834846,\n",
       " 0.01793755777180195,\n",
       " 0.002760429633781314,\n",
       " -0.022348662838339806,\n",
       " 0.02091086469590664,\n",
       " 0.01254931092262268,\n",
       " 0.018733231350779533,\n",
       " 0.0020868987776339054,\n",
       " 0.03548425808548927,\n",
       " -0.0066690025851130486,\n",
       " -0.007461186498403549,\n",
       " 0.0068749007768929005,\n",
       " -0.0019193885382264853,\n",
       " -0.00890596304088831,\n",
       " -0.010204167105257511,\n",
       " -0.017672333866357803,\n",
       " -0.021832171827554703,\n",
       " -0.004233124200254679,\n",
       " 0.013002985157072544,\n",
       " -0.008829187601804733,\n",
       " -2.9905245355621446e-06,\n",
       " -0.005656961351633072,\n",
       " -0.01208167802542448,\n",
       " -0.0006168216932564974,\n",
       " -0.00041768510709516704,\n",
       " -0.0007908752886578441,\n",
       " 0.002601643791422248,\n",
       " -0.00796371791511774,\n",
       " 0.002774388762190938,\n",
       " 0.017141884192824364,\n",
       " -0.018105069175362587,\n",
       " 0.004362246487289667,\n",
       " 0.03456295281648636,\n",
       " 0.012542331591248512,\n",
       " 0.004910144954919815,\n",
       " 0.006075737066566944,\n",
       " -0.0018234191229566932,\n",
       " 0.01136975921690464,\n",
       " -0.023451438173651695,\n",
       " 0.01230502501130104,\n",
       " -0.003083235817030072,\n",
       " 0.0003939108573831618,\n",
       " -0.0020066334400326014,\n",
       " -0.02392604947090149,\n",
       " -0.0012502198806032538,\n",
       " -0.004086552653461695,\n",
       " -0.015215516090393066,\n",
       " -0.010057595558464527,\n",
       " -0.02668996900320053,\n",
       " 0.01955682411789894,\n",
       " 0.001564301666803658,\n",
       " 0.0005963190924376249,\n",
       " -0.025615112856030464,\n",
       " -0.009227024391293526,\n",
       " 0.0035002666991204023,\n",
       " 0.024135438725352287,\n",
       " -0.010804412886500359,\n",
       " -0.0003494159609545022,\n",
       " -0.00029117995291016996,\n",
       " -0.023828335106372833,\n",
       " 0.0064107575453817844,\n",
       " -0.004355267155915499,\n",
       " 0.0004632705822587013,\n",
       " 0.00641773734241724,\n",
       " 0.007440248038619757,\n",
       " 0.009708615951240063,\n",
       " -0.00908743217587471,\n",
       " 0.22960074245929718,\n",
       " -0.008201023563742638,\n",
       " -0.0024166845250874758,\n",
       " 0.04271511733531952,\n",
       " -0.001392429112456739,\n",
       " 0.004781022202223539,\n",
       " 0.01891470141708851,\n",
       " 0.018481966108083725,\n",
       " -0.029146786779165268,\n",
       " 0.020589804276823997,\n",
       " 0.0054056961089372635,\n",
       " -0.005273083690553904,\n",
       " -0.012039801105856895,\n",
       " 0.0010984137188643217,\n",
       " 0.00012770477042067796,\n",
       " -0.0067283292300999165,\n",
       " -0.03554009646177292,\n",
       " -0.015410944819450378,\n",
       " -0.013365923427045345,\n",
       " -0.005241675768047571,\n",
       " 0.006330492440611124,\n",
       " 0.02220907062292099,\n",
       " -0.0109440041705966,\n",
       " -0.030626460909843445,\n",
       " 0.018398212268948555,\n",
       " 0.001374107669107616,\n",
       " -0.01400106679648161,\n",
       " 0.005981512367725372,\n",
       " 0.005733736790716648,\n",
       " 0.022432416677474976,\n",
       " -0.009701636619865894,\n",
       " 0.0008000360103324056,\n",
       " 0.0004571634344756603,\n",
       " -0.003013439942151308,\n",
       " -0.00653988029807806,\n",
       " -0.022264907136559486,\n",
       " 0.016569558531045914,\n",
       " -0.02473568357527256,\n",
       " 0.014950291253626347,\n",
       " 0.005290532484650612,\n",
       " 0.0125283719971776,\n",
       " -0.0167929045855999,\n",
       " 0.007147104945033789,\n",
       " -0.03556801378726959,\n",
       " 0.027904419228434563,\n",
       " -0.015173638239502907,\n",
       " ...]"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = embeddings.embed_query(text)\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413d1be8",
   "metadata": {},
   "source": [
    "Initialize ChromaDB Vector Store and Stores the chunks in Vector Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "3162366c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created with 141 vectors\n",
      "Persisted to: ./chroma_db_1\n"
     ]
    }
   ],
   "source": [
    "# Create a Chromadb vector store\n",
    "persist_directory='./chroma_db_1'\n",
    "\n",
    "# Initialize Chromadb with OpenAI embeddings\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    persist_directory=persist_directory,\n",
    "    collection_name='rag_collection'\n",
    ")\n",
    "\n",
    "print(f'Vector store created with {vectorstore._collection.count()} vectors')\n",
    "print(f'Persisted to: {persist_directory}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df271966",
   "metadata": {},
   "source": [
    "Test Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "4542cd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Python Programming Language'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Python Programming Language'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Python Programming Language')]"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'What is Python Programming Language?'\n",
    "\n",
    "similar_docs = vectorstore.similarity_search(query, k=3)\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "53fb567d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Introduction to Machine Learning'),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Introduction to Machine Learning'),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Introduction to Machine Learning')]"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query1 = 'What is Machine Learning?'\n",
    "similar_docs_1 = vectorstore.similarity_search(query1, k=3)\n",
    "similar_docs_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "c97dc273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is Machine Learning?\n",
      "\n",
      "Top 3 similar chunks\n",
      "\n",
      "----- Chunk 1 ----------\n",
      "Introduction to Machine Learning\n",
      "Source: data\\doc_2.txt\n",
      "\n",
      "----- Chunk 2 ----------\n",
      "Introduction to Machine Learning\n",
      "Source: data\\doc_2.txt\n",
      "\n",
      "----- Chunk 3 ----------\n",
      "Introduction to Machine Learning\n",
      "Source: data\\doc_2.txt\n"
     ]
    }
   ],
   "source": [
    "print(f'Query: {query1}')\n",
    "print(f'\\nTop {len(similar_docs_1)} similar chunks')\n",
    "\n",
    "for i, doc in enumerate(similar_docs_1):\n",
    "    print(f'\\n----- Chunk {i+1} ----------')\n",
    "    print(doc.page_content)\n",
    "    print(f'Source: {doc.metadata.get('source', 'Unknown')}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fd61cf",
   "metadata": {},
   "source": [
    "Similarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "2721cfb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Introduction to Machine Learning'),\n",
       "  0.17662833631038666),\n",
       " (Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Introduction to Machine Learning'),\n",
       "  0.17662833631038666),\n",
       " (Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Introduction to Machine Learning'),\n",
       "  0.17662833631038666)]"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_scores = vectorstore.similarity_search_with_score(query1, k=3)\n",
    "results_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1fbd58",
   "metadata": {},
   "source": [
    "Initialize LLM, RAG chain, Prompt Template, Query the RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "c1f2379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name='gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "054fa85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='In the context of artificial intelligence, LLM stands for Language Model (LM) and RAG stands for Retrieval-Augmented Generation. \\n\\nLanguage Models are AI models that are trained on vast amounts of text data to understand and generate human language. They are used in a variety of natural language processing tasks such as text generation, machine translation, and speech recognition.\\n\\nRAG, on the other hand, is a specific framework for language understanding and generation that combines the capabilities of language modeling with a retrieval mechanism. This allows the model to retrieve relevant information from a large knowledge base to generate more contextually relevant responses in tasks such as question answering and natural language generation.\\n\\nOverall, LLM and RAG are both important techniques in AI that help improve the understanding and generation of human language.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 156, 'prompt_tokens': 18, 'total_tokens': 174, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-Ck65M3fao7SsCc9X5mQjlU1hkYDDV', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--091f4be3-8c75-4bc9-b2f7-29d195d3a179-0', usage_metadata={'input_tokens': 18, 'output_tokens': 156, 'total_tokens': 174, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm.invoke('What is LLM and RAG in AI perspective?')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "075042b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000002688D95A690>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002688D95A810>, root_client=<openai.OpenAI object at 0x000002688FB6C5F0>, root_async_client=<openai.AsyncOpenAI object at 0x000002688FB6D220>, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models.base import init_chat_model\n",
    "\n",
    "llm = init_chat_model('openai:gpt-3.5-turbo')\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "6cc05a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='In AI perspective, LLM stands for Language Model and RAG stands for Retrieval-Augmented Generation. \\n\\nLanguage Models (LLMs) are algorithms that have been trained on vast amounts of text data to predict the next word in a sequence of text. They are designed to understand and generate human language, and have been used in a wide range of natural language processing tasks such as machine translation, text generation, question answering, and more.\\n\\nRetrieval-Augmented Generation (RAG) is a technique that combines language models with retrievers, which are algorithms that are able to retrieve relevant information from a large set of documents. By combining these two approaches, RAG is able to generate more contextually relevant and accurate responses to queries or prompts. This approach has been particularly effective in question answering tasks, where the model first retrieves relevant information from a large database of documents and then generates a response based on that retrieved information.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 185, 'prompt_tokens': 18, 'total_tokens': 203, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-Ck65OilRBsY8rPf9dM9DiGawy4nrv', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--4a6c44eb-75c7-4edc-8524-9b91fc5228ae-0', usage_metadata={'input_tokens': 18, 'output_tokens': 185, 'total_tokens': 203, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke('What is LLM and RAG in AI perspective?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "a1302c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "0c11358a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000002688EB28B90>, search_kwargs={'k': 3})"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert vectorstore into retriever\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs = {'k': 3} # Retrieve top 3 relevant chunks\n",
    ")\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "6a3b21ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"\\n    You are an AI assistant for question and answering tasks.\\n    Use the following retrieved context to answer the question.\\n    If you don't know the answer, say you don't know.\\n    Use 4 sentences maximum and keep the answer concise.\\n\\n    Context: {context}\\n\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Create prompt template\n",
    "system_prompt = '''\n",
    "    You are an AI assistant for question and answering tasks.\n",
    "    Use the following retrieved context to answer the question.\n",
    "    If you don't know the answer, say you don't know.\n",
    "    Use 4 sentences maximum and keep the answer concise.\n",
    "    \n",
    "    Context: {context}\n",
    "'''\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_prompt),\n",
    "    ('human', '{input}')\n",
    "])\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "81cbd1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"\\n    You are an AI assistant for question and answering tasks.\\n    Use the following retrieved context to answer the question.\\n    If you don't know the answer, say you don't know.\\n    Use 4 sentences maximum and keep the answer concise.\\n\\n    Context: {context}\\n\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000002688D95A690>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002688D95A810>, root_client=<openai.OpenAI object at 0x000002688FB6C5F0>, root_async_client=<openai.AsyncOpenAI object at 0x000002688FB6D220>, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# Create a document chain\n",
    "document_chain = create_stuff_documents_chain(\n",
    "    llm,\n",
    "    prompt\n",
    ")\n",
    "\n",
    "\n",
    "document_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "c4898585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000002688EB28B90>, search_kwargs={'k': 3}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"\\n    You are an AI assistant for question and answering tasks.\\n    Use the following retrieved context to answer the question.\\n    If you don't know the answer, say you don't know.\\n    Use 4 sentences maximum and keep the answer concise.\\n\\n    Context: {context}\\n\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000002688D95A690>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002688D95A810>, root_client=<openai.OpenAI object at 0x000002688FB6C5F0>, root_async_client=<openai.AsyncOpenAI object at 0x000002688FB6D220>, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "# Create RAG Chain\n",
    "rag_chain = create_retrieval_chain(\n",
    "    retriever,\n",
    "    document_chain\n",
    ")\n",
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "5aaa3c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Wht is machine learning?',\n",
       " 'context': [Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Introduction to Machine Learning'),\n",
       "  Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Introduction to Machine Learning'),\n",
       "  Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Introduction to Machine Learning')],\n",
       " 'answer': 'Machine learning is a branch of artificial intelligence that focuses on developing algorithms and statistical models to allow computers to improve their performance on a specific task without being explicitly programmed. It involves using data to train these models and make predictions or decisions without human intervention. Machine learning can be categorized into supervised learning, unsupervised learning, and reinforcement learning, depending on the type of data available for training. Overall, machine learning enables computers to learn and adapt from experience to perform tasks more accurately.'}"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke({\n",
    "    'input': 'Wht is machine learning?'\n",
    "})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "9ab52255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is javascript?',\n",
       " 'context': [Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Python Programming Language'),\n",
       "  Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Python Programming Language'),\n",
       "  Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Python Programming Language')],\n",
       " 'answer': \"I don't know.\"}"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1 = rag_chain.invoke({\n",
    "    'input': 'What is javascript?'\n",
    "})\n",
    "response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "e55e7a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is javascript?',\n",
       " 'context': [Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Python Programming Language'),\n",
       "  Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Python Programming Language'),\n",
       "  Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Python Programming Language')],\n",
       " 'answer': \"I don't know, as the context provided is about the Python Programming Language.\"}"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2 = rag_chain.invoke({\n",
    "    'input': 'What is javascript?'\n",
    "})\n",
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "59a677ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is ReactJs?',\n",
       " 'context': [Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='üåç Its clear syntax and strong community make it ideal for beginners and professionals alike.'),\n",
       "  Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='üåç Its clear syntax and strong community make it ideal for beginners and professionals alike.'),\n",
       "  Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='üåç Its clear syntax and strong community make it ideal for beginners and professionals alike.')],\n",
       " 'answer': 'ReactJs is a JavaScript library for building user interfaces. Its clear syntax and strong community make it ideal for beginners and professionals alike. ReactJs allows developers to create interactive user interfaces efficiently. It is widely used in web development for its component-based structure and virtual DOM.'}"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response3 = rag_chain.invoke({\n",
    "    'input': 'What is ReactJs?'\n",
    "})\n",
    "response3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "960f3438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Who is the present Nigeria president?',\n",
       " 'context': [Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Introduction to Machine Learning'),\n",
       "  Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Introduction to Machine Learning'),\n",
       "  Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Introduction to Machine Learning')],\n",
       " 'answer': \"I'm sorry, I do not have that information.\"}"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response4 = rag_chain.invoke({\n",
    "    'input': 'Who is the present Nigeria president?'\n",
    "})\n",
    "response4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "d643b893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What do you understand by Python Programming?\n",
      "********************************************************************************\n",
      "Answer: Python is a high-level programming language known for its readability and simplicity which allows developers to write clear and logical code. It supports multiple programming paradigms like procedural, object-oriented, and functional programming. Python's extensive standard library provides built-in modules for a wide range of tasks, making it versatile for various applications. Its dynamic typing and automatic memory management contribute to its ease of use for both beginners and experienced programmers.\n",
      "\n",
      "Retrieved Contact:\n",
      "\n",
      "... Source 1....\n",
      "Python Programming Language\n",
      "\n",
      "... Source 2....\n",
      "Python Programming Language\n",
      "\n",
      "... Source 3....\n",
      "Python Programming Language\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Question: List main types of machine learning\n",
      "********************************************************************************\n",
      "Answer: The main types of machine learning are supervised learning, unsupervised learning, semi-supervised learning, and reinforcement learning.\n",
      "\n",
      "Retrieved Contact:\n",
      "\n",
      "... Source 1....\n",
      "Introduction to Machine Learning\n",
      "\n",
      "... Source 2....\n",
      "Introduction to Machine Learning\n",
      "\n",
      "... Source 3....\n",
      "Introduction to Machine Learning\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Question: What is  deep learning?\n",
      "********************************************************************************\n",
      "Answer: Deep learning is a subset of machine learning that utilizes artificial neural networks to model and solve complex problems. It is inspired by the structure and function of the human brain and is capable of learning from large amounts of labeled data. Deep learning algorithms are able to automatically learn to represent data with multiple levels of abstraction. It is commonly used in various fields such as image and speech recognition, natural language processing, and autonomous vehicles.\n",
      "\n",
      "Retrieved Contact:\n",
      "\n",
      "... Source 1....\n",
      "Introduction to Deep Learning\n",
      "\n",
      "... Source 2....\n",
      "Introduction to Deep Learning\n",
      "\n",
      "... Source 3....\n",
      "Introduction to Deep Learning\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Question: What is django?\n",
      "********************************************************************************\n",
      "Answer: Django is a high-level Python web framework that enables rapid development of secure and maintainable websites. It follows the Model-View-Template (MVT) architectural pattern to separate data, logic, and presentation. Additionally, Django comes with built-in features like authentication, admin interface, and URL routing. It emphasizes security, helping developers avoid common threats like SQL injection and cross-site scripting.\n",
      "\n",
      "Retrieved Contact:\n",
      "\n",
      "... Source 1....\n",
      "üåê **Django** is a high-level Python web framework that enables rapid development of secure and maintainable websites.  \n",
      "    ‚öôÔ∏è It follows the Model-View-Template (MVT) architectural pattern to separate data, logic, and presentation.  \n",
      "    üöÄ Django comes with built-in features like authentication, admin interface, and URL routing.  \n",
      "    üõ°Ô∏è It emphasizes security, helping developers avoid common threats like SQL injection and cross-site scripting.\n",
      "\n",
      "... Source 2....\n",
      "üåê **Django** is a high-level Python web framework that enables rapid development of secure and maintainable websites.  \n",
      "    ‚öôÔ∏è It follows the Model-View-Template (MVT) architectural pattern to separate data, logic, and presentation.  \n",
      "    üöÄ Django comes with built-in features like authentication, admin interface, and URL routing.  \n",
      "    üõ°Ô∏è It emphasizes security, helping developers avoid common threats like SQL injection and cross-site scripting.\n",
      "\n",
      "... Source 3....\n",
      "üåê **Django** is a high-level Python web framework that enables rapid development of secure and maintainable websites.  \n",
      "    ‚öôÔ∏è It follows the Model-View-Template (MVT) architectural pattern to separate data, logic, and presentation.  \n",
      "    üöÄ Django comes with built-in features like authentication, admin interface, and URL routing.  \n",
      "    üõ°Ô∏è It emphasizes security, helping developers avoid common threats like SQL injection and cross-site scripting.\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Function for querying modern RAG System\n",
    "\n",
    "def query_rag_system(question):\n",
    "    \n",
    "    print(f'Question: {question}')\n",
    "    print('*' * 80)\n",
    "    \n",
    "    result = rag_chain.invoke({\n",
    "        'input': question\n",
    "    })\n",
    "    \n",
    "    print(f'Answer: {result['answer']}')\n",
    "    print('\\nRetrieved Contact:')\n",
    "    \n",
    "    for i, doc in enumerate(result['context']):\n",
    "        print(f'\\n... Source {i+1}....')\n",
    "        print(doc.page_content)\n",
    "        \n",
    "    return result\n",
    "\n",
    "# Test queries\n",
    "questions = [\n",
    "    'What do you understand by Python Programming?',\n",
    "    'List main types of machine learning',\n",
    "    'What is  deep learning?',\n",
    "    'What is django?'\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    result = query_rag_system(question)\n",
    "    print('\\n' + '=' * 100 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60e9062",
   "metadata": {},
   "source": [
    "Create RAG Chain Using LCEL (LangChain Expression LAnguage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "5309c510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "762685e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"\\n        You are an AI assistant for question and answering tasks.\\n        Use the following retrieved context to answer the question.\\n        If you don't know the answer, say you don't know.\\n        Use 4 sentences maximum and keep the answer concise.\\n\\n        Context: {context}\\n\\n        Question: {question}\\n\\n        Answer:\\n    \"), additional_kwargs={})])"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a custom prompt\n",
    "custom_prompt = ChatPromptTemplate.from_template(\n",
    "    '''\n",
    "        You are an AI assistant for question and answering tasks.\n",
    "        Use the following retrieved context to answer the question.\n",
    "        If you don't know the answer, say you don't know.\n",
    "        Use 4 sentences maximum and keep the answer concise.\n",
    "        \n",
    "        Context: {context}\n",
    "        \n",
    "        Question: {question}\n",
    "        \n",
    "        Answer:\n",
    "    '''\n",
    ")\n",
    "custom_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "c7453aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the output documents for the prompt\n",
    "\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "1ee15d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000002688EB28B90>, search_kwargs={'k': 3})\n",
       "           | RunnableLambda(format_docs),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"\\n        You are an AI assistant for question and answering tasks.\\n        Use the following retrieved context to answer the question.\\n        If you don't know the answer, say you don't know.\\n        Use 4 sentences maximum and keep the answer concise.\\n\\n        Context: {context}\\n\\n        Question: {question}\\n\\n        Answer:\\n    \"), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000002688D95A690>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002688D95A810>, root_client=<openai.OpenAI object at 0x000002688FB6C5F0>, root_async_client=<openai.AsyncOpenAI object at 0x000002688FB6D220>, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build RAG using LCEL\n",
    "rag_chain_lcel = (\n",
    "    {\n",
    "        'context': retriever | format_docs, \n",
    "        'question': RunnablePassthrough()\n",
    "    }\n",
    "    | custom_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_lcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "be44e8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LLM stands for Large Language Model in the AI perspective. It refers to models that are trained on vast amounts of text data to understand and generate human-like language. LLMs are used for a variety of natural language processing tasks such as text generation, translation, and summarization. They have been a significant advancement in the field of AI in recent years.'"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain_lcel.invoke('What is LLM in AI perspective?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "7b5a6849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine learning is a subset of artificial intelligence that focuses on developing algorithms and statistical models to enable computers to learn from and make decisions or predictions based on data. It involves training computers to recognize patterns and make decisions without being explicitly programmed to do so. Machine learning algorithms use data to improve their performance over time through experience. This technology is widely used in various applications such as recommendation systems, image recognition, and natural language processing.'"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain_lcel.invoke('What is machine learning?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006e79c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a609996",
   "metadata": {},
   "source": [
    "Adding New Documents To Existing Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "b292c1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nComputer vision \\n\\nComputer vision is a field of artificial intelligence that\\nenables computers to derive meaningful information from digital\\nimages, videos, and other visual inputs. Its primary goal is to\\nreplicate the complexity of the human visual system, allowing\\nmachines to \"see\" and understand their surroundings. Instead of \\nperceiving an image as a whole picture, computers analyze visual\\ndata as vast arrays of numerical pixel values representing color \\nand brightness. By utilizing deep learning models, particularly \\nConvolutional Neural Networks (CNNs), the system learns to \\nidentify patterns, edges, and textures within these numbers.\\n'"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_document = \"\"\"\n",
    "Computer vision \n",
    "\n",
    "Computer vision is a field of artificial intelligence that\n",
    "enables computers to derive meaningful information from digital\n",
    "images, videos, and other visual inputs. Its primary goal is to\n",
    "replicate the complexity of the human visual system, allowing\n",
    "machines to \"see\" and understand their surroundings. Instead of \n",
    "perceiving an image as a whole picture, computers analyze visual\n",
    "data as vast arrays of numerical pixel values representing color \n",
    "and brightness. By utilizing deep learning models, particularly \n",
    "Convolutional Neural Networks (CNNs), the system learns to \n",
    "identify patterns, edges, and textures within these numbers.\n",
    "\"\"\"\n",
    "\n",
    "new_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "58da8eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'manual_addition', 'topic': 'computer_vision'}, page_content='\\nComputer vision \\n\\nComputer vision is a field of artificial intelligence that\\nenables computers to derive meaningful information from digital\\nimages, videos, and other visual inputs. Its primary goal is to\\nreplicate the complexity of the human visual system, allowing\\nmachines to \"see\" and understand their surroundings. Instead of \\nperceiving an image as a whole picture, computers analyze visual\\ndata as vast arrays of numerical pixel values representing color \\nand brightness. By utilizing deep learning models, particularly \\nConvolutional Neural Networks (CNNs), the system learns to \\nidentify patterns, edges, and textures within these numbers.\\n')"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_doc = Document(\n",
    "    page_content=new_document,\n",
    "    metadata={'source': 'manual_addition', 'topic': 'computer_vision'}\n",
    ")\n",
    "\n",
    "new_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "5937b534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'manual_addition', 'topic': 'computer_vision'}, page_content='Computer vision \\n\\nComputer vision is a field of artificial intelligence that\\nenables computers to derive meaningful information from digital\\nimages, videos, and other visual inputs. Its primary goal is to\\nreplicate the complexity of the human visual system, allowing\\nmachines to \"see\" and understand their surroundings. Instead of \\nperceiving an image as a whole picture, computers analyze visual\\ndata as vast arrays of numerical pixel values representing color \\nand brightness. By utilizing deep learning models, particularly \\nConvolutional Neural Networks (CNNs), the system learns to \\nidentify patterns, edges, and textures within these numbers.')]"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the documents\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "new_chunks = text_splitter.split_documents([new_doc])\n",
    "\n",
    "new_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "a16ec89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6ba953af-f469-407c-8e21-783638791e5f']"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add new document to vectorstore\n",
    "\n",
    "vectorstore.add_documents(new_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "3d79d124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1 new chunks to the vector store\n",
      "Total vectors now: 142\n"
     ]
    }
   ],
   "source": [
    "print(f'Added {len(new_chunks)} new chunks to the vector store')\n",
    "print(f'Total vectors now: {vectorstore._collection.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "2eb1673c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the main concept of computer vision?\n",
      "********************************************************************************\n",
      "Answer: The main concept of computer vision is to enable computers to understand and derive meaningful information from digital images and videos. It aims to replicate the complexity of the human visual system, allowing machines to \"see\" and comprehend their surroundings. By analyzing visual data as numerical pixel values, computers can identify patterns, edges, and textures within images. Deep learning models, especially Convolutional Neural Networks (CNNs), are commonly used in computer vision to achieve this goal.\n",
      "\n",
      "Retrieved Contact:\n",
      "\n",
      "... Source 1....\n",
      "Computer vision \n",
      "\n",
      "Computer vision is a field of artificial intelligence that\n",
      "enables computers to derive meaningful information from digital\n",
      "images, videos, and other visual inputs. Its primary goal is to\n",
      "replicate the complexity of the human visual system, allowing\n",
      "machines to \"see\" and understand their surroundings. Instead of \n",
      "perceiving an image as a whole picture, computers analyze visual\n",
      "data as vast arrays of numerical pixel values representing color \n",
      "and brightness. By utilizing deep learning models, particularly \n",
      "Convolutional Neural Networks (CNNs), the system learns to \n",
      "identify patterns, edges, and textures within these numbers.\n",
      "\n",
      "... Source 2....\n",
      "Computer vision \n",
      "\n",
      "Computer vision is a field of artificial intelligence that\n",
      "enables computers to derive meaningful information from digital\n",
      "images, videos, and other visual inputs. Its primary goal is to\n",
      "replicate the complexity of the human visual system, allowing\n",
      "machines to \"see\" and understand their surroundings. Instead of \n",
      "perceiving an image as a whole picture, computers analyze visual\n",
      "data as vast arrays of numerical pixel values representing color \n",
      "and brightness. By utilizing deep learning models, particularly \n",
      "Convolutional Neural Networks (CNNs), the system learns to \n",
      "identify patterns, edges, and textures within these numbers.\n",
      "\n",
      "... Source 3....\n",
      "Computer vision \n",
      "\n",
      "Computer vision is a field of artificial intelligence that\n",
      "enables computers to derive meaningful information from digital\n",
      "images, videos, and other visual inputs. Its primary goal is to\n",
      "replicate the complexity of the human visual system, allowing\n",
      "machines to \"see\" and understand their surroundings. Instead of \n",
      "perceiving an image as a whole picture, computers analyze visual\n",
      "data as vast arrays of numerical pixel values representing color \n",
      "and brightness. By utilizing deep learning models, particularly \n",
      "Convolutional Neural Networks (CNNs), the system learns to \n",
      "identify patterns, edges, and textures within these numbers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the main concept of computer vision?',\n",
       " 'context': [Document(metadata={'topic': 'computer_vision', 'source': 'manual_addition'}, page_content='Computer vision \\n\\nComputer vision is a field of artificial intelligence that\\nenables computers to derive meaningful information from digital\\nimages, videos, and other visual inputs. Its primary goal is to\\nreplicate the complexity of the human visual system, allowing\\nmachines to \"see\" and understand their surroundings. Instead of \\nperceiving an image as a whole picture, computers analyze visual\\ndata as vast arrays of numerical pixel values representing color \\nand brightness. By utilizing deep learning models, particularly \\nConvolutional Neural Networks (CNNs), the system learns to \\nidentify patterns, edges, and textures within these numbers.'),\n",
       "  Document(metadata={'topic': 'computer_vision', 'source': 'manual_addition'}, page_content='Computer vision \\n\\nComputer vision is a field of artificial intelligence that\\nenables computers to derive meaningful information from digital\\nimages, videos, and other visual inputs. Its primary goal is to\\nreplicate the complexity of the human visual system, allowing\\nmachines to \"see\" and understand their surroundings. Instead of \\nperceiving an image as a whole picture, computers analyze visual\\ndata as vast arrays of numerical pixel values representing color \\nand brightness. By utilizing deep learning models, particularly \\nConvolutional Neural Networks (CNNs), the system learns to \\nidentify patterns, edges, and textures within these numbers.'),\n",
       "  Document(metadata={'source': 'manual_addition', 'topic': 'computer_vision'}, page_content='Computer vision \\n\\nComputer vision is a field of artificial intelligence that\\nenables computers to derive meaningful information from digital\\nimages, videos, and other visual inputs. Its primary goal is to\\nreplicate the complexity of the human visual system, allowing\\nmachines to \"see\" and understand their surroundings. Instead of \\nperceiving an image as a whole picture, computers analyze visual\\ndata as vast arrays of numerical pixel values representing color \\nand brightness. By utilizing deep learning models, particularly \\nConvolutional Neural Networks (CNNs), the system learns to \\nidentify patterns, edges, and textures within these numbers.')],\n",
       " 'answer': 'The main concept of computer vision is to enable computers to understand and derive meaningful information from digital images and videos. It aims to replicate the complexity of the human visual system, allowing machines to \"see\" and comprehend their surroundings. By analyzing visual data as numerical pixel values, computers can identify patterns, edges, and textures within images. Deep learning models, especially Convolutional Neural Networks (CNNs), are commonly used in computer vision to achieve this goal.'}"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query with the updated vector\n",
    "\n",
    "new_question = 'What is the main concept of computer vision?'\n",
    "\n",
    "result = query_rag_system(new_question)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a87b080",
   "metadata": {},
   "source": [
    "Advanced RAG Techniques: Conversational Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "fcb7e3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "eab06559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt with addition of chat history\n",
    "contextualize_q_system_prompt = '''\n",
    "    Given a chat history and the latest user question\n",
    "    which might reference context in the chat history, formulate a standalone question\n",
    "    which can be understood without the chat history. Do not answer the question,\n",
    "    just reformulate it if number or otherwise return it as it.\n",
    "'''\n",
    "\n",
    "# Create chat prompt\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', contextualize_q_system_prompt),\n",
    "    MessagesPlaceholder('chat_history'),\n",
    "    ('human', '{input}'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "fae45cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
       "| VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000002688EB28B90>, search_kwargs={'k': 3}))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000268F6DF2CA0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='\\n    Given a chat history and the latest user question\\n    which might reference context in the chat history, formulate a standalone question\\n    which can be understood without the chat history. Do not answer the question,\\n    just reformulate it if number or otherwise return it as it.\\n'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000002688D95A690>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002688D95A810>, root_client=<openai.OpenAI object at 0x000002688FB6C5F0>, root_async_client=<openai.AsyncOpenAI object at 0x000002688FB6D220>, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()\n",
       "| VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000002688EB28B90>, search_kwargs={'k': 3})), kwargs={}, config={'run_name': 'chat_retriever_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create history aware retriever\n",
    "\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm,\n",
    "    retriever,\n",
    "    contextualize_q_prompt\n",
    ")\n",
    "\n",
    "history_aware_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "47144532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversational RAG chain created successfully\n"
     ]
    }
   ],
   "source": [
    "# Create a new document chain with history\n",
    "\n",
    "qa_system_prompt = '''\n",
    "    You are an AI assistant for question and answering tasks.\n",
    "    Use the following retrieved context to answer the question.\n",
    "    If you don't know the answer, say you don't know.\n",
    "    Use 4 sentences maximum and keep the answer concise.\n",
    "    \n",
    "    Context: {context}\n",
    "'''\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', qa_system_prompt),\n",
    "    MessagesPlaceholder('chat_history'),\n",
    "    ('human', '{input}'),\n",
    "])\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(\n",
    "    llm,\n",
    "    qa_prompt\n",
    ")\n",
    "\n",
    "# Create concersational RAG chain\n",
    "conversational_rag_chain = create_retrieval_chain(\n",
    "    history_aware_retriever,\n",
    "    question_answer_chain\n",
    ")\n",
    "\n",
    "print('Conversational RAG chain created successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "06f82734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is machine learning?\n",
      "A: Machine learning is a branch of artificial intelligence that focuses on developing systems that can learn from data and improve over time without being explicitly programmed. It involves algorithms that enable computers to make decisions or predictions based on patterns in data. Machine learning is used in a wide range of applications, from recommendation systems to image recognition. Overall, it is about creating models that can learn from and make predictions or decisions based on data.\n"
     ]
    }
   ],
   "source": [
    "# 1st Question\n",
    "chat_history = []\n",
    "result_1 = conversational_rag_chain.invoke({\n",
    "    'chat_history': chat_history,\n",
    "    'input': 'What is machine learning?'\n",
    "})\n",
    "\n",
    "print(f'Q: What is machine learning?')\n",
    "print(f'A: {result_1['answer']}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "fa435cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "18ce3072",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.extend([\n",
    "    HumanMessage(content='What is machine learning?'),\n",
    "    AIMessage(content=result_1['answer'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "dba459e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is machine learning?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Machine learning is a branch of artificial intelligence that focuses on developing systems that can learn from data and improve over time without being explicitly programmed. It involves algorithms that enable computers to make decisions or predictions based on patterns in data. Machine learning is used in a wide range of applications, from recommendation systems to image recognition. Overall, it is about creating models that can learn from and make predictions or decisions based on data.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "6e522066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='What is machine learning?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Machine learning is a branch of artificial intelligence that focuses on developing systems that can learn from data and improve over time without being explicitly programmed. It involves algorithms that enable computers to make decisions or predictions based on patterns in data. Machine learning is used in a wide range of applications, from recommendation systems to image recognition. Overall, it is about creating models that can learn from and make predictions or decisions based on data.', additional_kwargs={}, response_metadata={})],\n",
       " 'input': 'What are its main?',\n",
       " 'context': [Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Introduction to Machine Learning'),\n",
       "  Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Introduction to Machine Learning'),\n",
       "  Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Introduction to Machine Learning')],\n",
       " 'answer': \"Machine learning's main goal is to develop models that can analyze data, learn from it, and make predictions or decisions. It involves training algorithms to recognize patterns in data so they can make accurate predictions on new, unseen data. Machine learning also focuses on optimizing models to improve their performance over time and adapting to new data. Overall, its main purpose is to enable computers to learn from data and make decisions or predictions without being explicitly programmed.\"}"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next question\n",
    "result_2 = conversational_rag_chain.invoke({\n",
    "    'chat_history': chat_history,\n",
    "    'input': 'What are its main?'\n",
    "})\n",
    "\n",
    "result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "3e7e3ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Machine learning's main goal is to develop models that can analyze data, learn from it, and make predictions or decisions. It involves training algorithms to recognize patterns in data so they can make accurate predictions on new, unseen data. Machine learning also focuses on optimizing models to improve their performance over time and adapting to new data. Overall, its main purpose is to enable computers to learn from data and make decisions or predictions without being explicitly programmed.\""
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_2['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e23201c",
   "metadata": {},
   "source": [
    "Build RAG Chain with LCEL Using GROQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "7a960402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002688FB6CD70>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002688FB6E5D0>, model_name='llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_groq import ChatGroq\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# llm = init_chat_model(\n",
    "#     model=\"gemma2-27b-it\",\n",
    "#     model_provider=\"groq\",\n",
    "#     api_key=groq_api_key\n",
    "# )\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama3-8b-8192\",\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\")\n",
    ")\n",
    "\n",
    "\n",
    "llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic RAG Chain with LCEL\n",
    "\n",
    "simple_prompt = ChatPromptTemplate.from_template(\n",
    "    '''\n",
    "    Answer the question base only on the following context:\n",
    "    Context: {context}\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Answer:\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "b187c496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000002688EB28B90>, search_kwargs={'k': 3})"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create basic retriever\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type='similarity',\n",
    "    search_kwargs={'k': 3}\n",
    ")\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "e5ad0bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "# Format documents for the prompt\n",
    "\n",
    "def format_docs(docs: List[Document]) -> str:\n",
    "    '''Format documents for insertion into prompt'''\n",
    "    \n",
    "    formatted = []\n",
    "    \n",
    "    for i, doc in enumerate(docs):\n",
    "        source = doc.metadata.get('source', 'Unknown')\n",
    "        formatted.append(f'Document {i+1} (source: {source}):\\ndoc.page_content')\n",
    "        \n",
    "    return '\\n\\n'.join(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "0fa5d0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000002688EB28B90>, search_kwargs={'k': 3})\n",
       "           | RunnableLambda(format_docs),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='\\n    Answer the question base only on the following context:\\n    Context: {context}\\n\\n    Question: {question}\\n\\n    Answer:\\n    '), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002688FB6CD70>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002688FB6E5D0>, model_name='llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_rag_chain = (\n",
    "    {\n",
    "        'context': retriever | format_docs,\n",
    "        'question': RunnablePassthrough()\n",
    "    }\n",
    "    | simple_prompt\n",
    "    | llm\n",
    ")\n",
    "basic_rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "ec21c6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Conversational Rag Chain\n",
    "\n",
    "conversational_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'You are a helpful AI assistant. Use the provided context to answer the questions.'),\n",
    "    ('placeholder', '{chat_history}'),\n",
    "    ('human', 'Context: {context}\\n\\nQuestion: {input}')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "218a59fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  context: RunnableLambda(lambda x: format_docs(retriever.invoke(x['input'])))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000268F6DF2CA0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful AI assistant. Use the provided context to answer the questions.'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template='Context: {context}\\n\\nQuestion: {input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002688FB6CD70>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002688FB6E5D0>, model_name='llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_conversational_rag():\n",
    "    '''Create a conversational RAG chain with memory'''\n",
    "    return (\n",
    "        RunnablePassthrough.assign(\n",
    "            context=lambda x: format_docs(retriever.invoke(x['input']))\n",
    "        )\n",
    "        | conversational_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "conversational_rag = create_conversational_rag()\n",
    "conversational_rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "e592681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tet function for different chain types\n",
    "\n",
    "def test_rag_chain(question: str):\n",
    "    \n",
    "    '''Test all RAG chains'''\n",
    "    print(f'Question: {question}')\n",
    "    print('-' * 90)\n",
    "    \n",
    "    print('\\n#1. Basic RAG Chain')\n",
    "    answer = basic_rag_chain.invoke(question)\n",
    "    print(f'Answer: {answer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "e0b38bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Differentiate between machine learning and deep learning\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "#1. Basic RAG Chain\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[507]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtest_rag_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mDifferentiate between machine learning and deep learning\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[506]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mtest_rag_chain\u001b[39m\u001b[34m(question)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m * \u001b[32m90\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m#1. Basic RAG Chain\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m answer = \u001b[43mbasic_rag_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mAnswer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manswer\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\RAG_project\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3082\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3080\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3081\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3082\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3084\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\RAG_project\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:393\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    381\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    383\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    388\u001b[39m     **kwargs: Any,\n\u001b[32m    389\u001b[39m ) -> BaseMessage:\n\u001b[32m    390\u001b[39m     config = ensure_config(config)\n\u001b[32m    391\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    392\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    403\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\RAG_project\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1019\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1010\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1011\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1012\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1016\u001b[39m     **kwargs: Any,\n\u001b[32m   1017\u001b[39m ) -> LLMResult:\n\u001b[32m   1018\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1019\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\RAG_project\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:837\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    834\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    835\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    836\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m837\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    843\u001b[39m         )\n\u001b[32m    844\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    845\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\RAG_project\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1085\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1083\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1084\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1085\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1086\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1087\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1088\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1089\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\RAG_project\\.venv\\Lib\\site-packages\\langchain_groq\\chat_models.py:527\u001b[39m, in \u001b[36mChatGroq._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    522\u001b[39m message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    523\u001b[39m params = {\n\u001b[32m    524\u001b[39m     **params,\n\u001b[32m    525\u001b[39m     **kwargs,\n\u001b[32m    526\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m527\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\RAG_project\\.venv\\Lib\\site-packages\\groq\\resources\\chat\\completions.py:378\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, exclude_domains, frequency_penalty, function_call, functions, include_domains, include_reasoning, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    185\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    186\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    233\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    234\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    235\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    236\u001b[39m \u001b[33;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    237\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    376\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/openai/v1/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_reasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_reasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msearch_settings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\RAG_project\\.venv\\Lib\\site-packages\\groq\\_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\RAG_project\\.venv\\Lib\\site-packages\\groq\\_base_client.py:1044\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1041\u001b[39m             err.response.read()\n\u001b[32m   1043\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1046\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': 'The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}"
     ]
    }
   ],
   "source": [
    "test_rag_chain('Differentiate between machine learning and deep learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155220c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
