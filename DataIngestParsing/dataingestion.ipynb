{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84353511",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e4e866a",
   "metadata": {},
   "source": [
    "Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4e8635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "from langchain_core.documents import Document \n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter, TokenTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aacd410",
   "metadata": {},
   "source": [
    "###  Ingesting And Parsing Text Data Using Document Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8955112e",
   "metadata": {},
   "source": [
    "Document Structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fcd4412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a basic document\n",
    "doc = Document(\n",
    "    page_content='Welcome to Generative AI and FullStack Development. You are welcome',\n",
    "    metadata = {\n",
    "        'source': 'rag_example.txt',\n",
    "        'page': 1,\n",
    "        'author':'Saheed Oladiipo',\n",
    "        'date_created': '2025-02-12',\n",
    "        'custom_field': 'any_value'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6b55ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Structure\n",
      "Content page: Welcome to Generative AI and FullStack Development. You are welcome\n",
      "Content Metadata: {'source': 'rag_example.txt', 'page': 1, 'author': 'Saheed Oladiipo', 'date_created': '2025-02-12', 'custom_field': 'any_value'}\n"
     ]
    }
   ],
   "source": [
    "print('Document Structure')\n",
    "print(f'Content page: {doc.page_content}')\n",
    "print(f'Content Metadata: {doc.metadata}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9969010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7feb40",
   "metadata": {},
   "source": [
    "Read Text Files in .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7000de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basic txt file\n",
    "os.makedirs('data/text_files', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cab7bee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = {\n",
    "    'data/text_files/python.txt': \"\"\"Of course. Python is the undisputed lingua franca for Generative AI, and its ecosystem of libraries makes it incredibly powerful for building applications like RAG systems, image generators, and more.\n",
    "\n",
    "Here is a breakdown of the essential Python libraries, concepts, and resources for Generative AI, moving from foundational to advanced.\n",
    "\n",
    "The Core Python Stack for Generative AI\n",
    "Your toolkit will primarily consist of these libraries:\n",
    "\n",
    "Core Numerical & Deep Learning Framework:\n",
    "\n",
    "PyTorch (torch): Developed by Meta, it's the most popular framework for cutting-edge AI research, including most new LLMs. Its dynamic computation graph (eager execution) is very intuitive for debugging and experimentation.\n",
    "\n",
    "TensorFlow (tensorflow): Developed by Google, it's a very powerful and production-hardened framework. While its market share in research has been overtaken by PyTorch, it's still widely used, especially with its high-level API Keras.\n",
    "\n",
    "JAX: Gaining rapid traction in research for its incredible speed and composable transformations (gradients, jit, vmap). It's used by Google DeepMind for models like Gemini.\n",
    "\n",
    "Recommendation for Beginners: Start with PyTorch. Most tutorials, research code, and pre-trained models are released in PyTorch first.\n",
    "\n",
    "The Hugging Face Ecosystem (transformers, datasets, accelerate): This is non-negotiable for working with LLMs. It provides a unified and incredibly simple API to thousands of pre-trained models.\n",
    "\n",
    "transformers: The main library for downloading and using pre-trained models (for text, vision, audio) for tasks like text generation, summarization, and classification.\n",
    "\n",
    "datasets: Provides easy access to thousands of datasets for training and evaluation.\n",
    "\n",
    "accelerate: Makes it trivial to scale your training or inference from a CPU to a single GPU to multiple GPUs without changing your code.\n",
    "\n",
    "peft: Library for Parameter-Efficient Fine-Tuning (e.g., LoRA), essential for fine-tuning large models on consumer hardware.\n",
    "\n",
    "evaluate: For standard evaluation metrics.\n",
    "\n",
    "Vector Databases & Similarity Search: Critical for the \"Retrieval\" in RAG.\n",
    "\n",
    "ChromaDB: Very popular, open-source, and easy-to-use. Great for getting started.\n",
    "\n",
    "FAISS (by Meta): A library for efficient similarity search and clustering of dense vectors. It's often used as an in-memory index.\n",
    "\n",
    "Pinecone, Weaviate, Qdrant: Managed/self-hosted vector databases that are production-ready and offer more features like persistence, hybrid search, and scalability.\n",
    "\n",
    "Web Frameworks for Building APIs & Applications:\n",
    "\n",
    "FastAPI: The modern standard for building high-performance APIs to serve your AI models. It automatically generates OpenAPI documentation and is asynchronous.\n",
    "\n",
    "Streamlit: The fastest way to turn your Python scripts into interactive web apps. Perfect for building prototypes, demos, and internal tools in minutes.\n",
    "\n",
    "Gradio: Similar to Streamlit, great for quickly creating a UI to demo your models, often used with Hugging Face Spaces.\n",
    "\n",
    "Essential Utilities:\n",
    "\n",
    "numpy: The fundamental package for numerical computation in Python.\n",
    "\n",
    "pandas: For data manipulation and analysis on your training data or outputs.\n",
    "\n",
    "tqdm: For adding progress bars to your loops, which is incredibly useful for tracking long-running training/inference tasks.\n",
    "\n",
    "python-dotenv: For managing environment variables (e.g., API keys for OpenAI, Pinecone) securely.\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf4936a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text file successfully created\n"
     ]
    }
   ],
   "source": [
    "for filepath, content in texts.items():\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "print('Text file successfully created')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb63998d",
   "metadata": {},
   "source": [
    "Read Single File Using TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3198a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.text.TextLoader at 0x18074597b60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load single text file\n",
    "loader = TextLoader('data/text_files/python.txt', encoding='utf-8')\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61ab7d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[Document(metadata={'source': 'data/text_files/python.txt'}, page_content='Of course. Python is the undisputed lingua franca for Generative AI, and its ecosystem of libraries makes it incredibly powerful for building applications like RAG systems, image generators, and more.\\n\\nHere is a breakdown of the essential Python libraries, concepts, and resources for Generative AI, moving from foundational to advanced.\\n\\nThe Core Python Stack for Generative AI\\nYour toolkit will primarily consist of these libraries:\\n\\nCore Numerical & Deep Learning Framework:\\n\\nPyTorch (torch): Developed by Meta, it\\'s the most popular framework for cutting-edge AI research, including most new LLMs. Its dynamic computation graph (eager execution) is very intuitive for debugging and experimentation.\\n\\nTensorFlow (tensorflow): Developed by Google, it\\'s a very powerful and production-hardened framework. While its market share in research has been overtaken by PyTorch, it\\'s still widely used, especially with its high-level API Keras.\\n\\nJAX: Gaining rapid traction in research for its incredible speed and composable transformations (gradients, jit, vmap). It\\'s used by Google DeepMind for models like Gemini.\\n\\nRecommendation for Beginners: Start with PyTorch. Most tutorials, research code, and pre-trained models are released in PyTorch first.\\n\\nThe Hugging Face Ecosystem (transformers, datasets, accelerate): This is non-negotiable for working with LLMs. It provides a unified and incredibly simple API to thousands of pre-trained models.\\n\\ntransformers: The main library for downloading and using pre-trained models (for text, vision, audio) for tasks like text generation, summarization, and classification.\\n\\ndatasets: Provides easy access to thousands of datasets for training and evaluation.\\n\\naccelerate: Makes it trivial to scale your training or inference from a CPU to a single GPU to multiple GPUs without changing your code.\\n\\npeft: Library for Parameter-Efficient Fine-Tuning (e.g., LoRA), essential for fine-tuning large models on consumer hardware.\\n\\nevaluate: For standard evaluation metrics.\\n\\nVector Databases & Similarity Search: Critical for the \"Retrieval\" in RAG.\\n\\nChromaDB: Very popular, open-source, and easy-to-use. Great for getting started.\\n\\nFAISS (by Meta): A library for efficient similarity search and clustering of dense vectors. It\\'s often used as an in-memory index.\\n\\nPinecone, Weaviate, Qdrant: Managed/self-hosted vector databases that are production-ready and offer more features like persistence, hybrid search, and scalability.\\n\\nWeb Frameworks for Building APIs & Applications:\\n\\nFastAPI: The modern standard for building high-performance APIs to serve your AI models. It automatically generates OpenAPI documentation and is asynchronous.\\n\\nStreamlit: The fastest way to turn your Python scripts into interactive web apps. Perfect for building prototypes, demos, and internal tools in minutes.\\n\\nGradio: Similar to Streamlit, great for quickly creating a UI to demo your models, often used with Hugging Face Spaces.\\n\\nEssential Utilities:\\n\\nnumpy: The fundamental package for numerical computation in Python.\\n\\npandas: For data manipulation and analysis on your training data or outputs.\\n\\ntqdm: For adding progress bars to your loops, which is incredibly useful for tracking long-running training/inference tasks.\\n\\npython-dotenv: For managing environment variables (e.g., API keys for OpenAI, Pinecone) securely.')]\n"
     ]
    }
   ],
   "source": [
    "documents = loader.load()\n",
    "print(type(documents))\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f85d84bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document\n",
      "\n",
      "Content preview: Of course. Python is the undisputed lingua franca for Generative AI, a....\n",
      "\n",
      "Metadata: {'source': 'data/text_files/python.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(f'Loaded {len(documents)} document\\n')\n",
    "print(f'Content preview: {documents[0].page_content[:70]}....\\n')\n",
    "print(f'Metadata: {documents[0].metadata}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350c5bd3",
   "metadata": {},
   "source": [
    "Extracting/Loading Multiple Text Files Using DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "933c3a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 510.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 documents\n",
      "\n",
      "Document: 1\n",
      " Source: data\\text_files\\python.txt\n",
      " Length: 3342 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load all text file in the directory\n",
    "loader_dir = DirectoryLoader(\n",
    "    'data/text_files',\n",
    "    glob='**/*.txt', # Patterns to match the file\n",
    "    loader_cls=TextLoader, #loader class used\n",
    "    loader_kwargs={'encoding': 'utf-8'},\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "documents = loader_dir.load()\n",
    "\n",
    "print(f'Loaded {len(documents)} documents')\n",
    "\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f'\\nDocument: {i+1}')\n",
    "    print(f' Source: {doc.metadata['source']}')\n",
    "    print(f' Length: {len(doc.page_content)} characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee3f2a3",
   "metadata": {},
   "source": [
    "Text Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93bc5b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Of course. Python is the undisputed lingua franca for Generative AI, and its ecosystem of libraries makes it incredibly powerful for building applications like RAG systems, image generators, and more.\\n\\nHere is a breakdown of the essential Python libraries, concepts, and resources for Generative AI, moving from foundational to advanced.\\n\\nThe Core Python Stack for Generative AI\\nYour toolkit will primarily consist of these libraries:\\n\\nCore Numerical & Deep Learning Framework:\\n\\nPyTorch (torch): Developed by Meta, it\\'s the most popular framework for cutting-edge AI research, including most new LLMs. Its dynamic computation graph (eager execution) is very intuitive for debugging and experimentation.\\n\\nTensorFlow (tensorflow): Developed by Google, it\\'s a very powerful and production-hardened framework. While its market share in research has been overtaken by PyTorch, it\\'s still widely used, especially with its high-level API Keras.\\n\\nJAX: Gaining rapid traction in research for its incredible speed and composable transformations (gradients, jit, vmap). It\\'s used by Google DeepMind for models like Gemini.\\n\\nRecommendation for Beginners: Start with PyTorch. Most tutorials, research code, and pre-trained models are released in PyTorch first.\\n\\nThe Hugging Face Ecosystem (transformers, datasets, accelerate): This is non-negotiable for working with LLMs. It provides a unified and incredibly simple API to thousands of pre-trained models.\\n\\ntransformers: The main library for downloading and using pre-trained models (for text, vision, audio) for tasks like text generation, summarization, and classification.\\n\\ndatasets: Provides easy access to thousands of datasets for training and evaluation.\\n\\naccelerate: Makes it trivial to scale your training or inference from a CPU to a single GPU to multiple GPUs without changing your code.\\n\\npeft: Library for Parameter-Efficient Fine-Tuning (e.g., LoRA), essential for fine-tuning large models on consumer hardware.\\n\\nevaluate: For standard evaluation metrics.\\n\\nVector Databases & Similarity Search: Critical for the \"Retrieval\" in RAG.\\n\\nChromaDB: Very popular, open-source, and easy-to-use. Great for getting started.\\n\\nFAISS (by Meta): A library for efficient similarity search and clustering of dense vectors. It\\'s often used as an in-memory index.\\n\\nPinecone, Weaviate, Qdrant: Managed/self-hosted vector databases that are production-ready and offer more features like persistence, hybrid search, and scalability.\\n\\nWeb Frameworks for Building APIs & Applications:\\n\\nFastAPI: The modern standard for building high-performance APIs to serve your AI models. It automatically generates OpenAPI documentation and is asynchronous.\\n\\nStreamlit: The fastest way to turn your Python scripts into interactive web apps. Perfect for building prototypes, demos, and internal tools in minutes.\\n\\nGradio: Similar to Streamlit, great for quickly creating a UI to demo your models, often used with Hugging Face Spaces.\\n\\nEssential Utilities:\\n\\nnumpy: The fundamental package for numerical computation in Python.\\n\\npandas: For data manipulation and analysis on your training data or outputs.\\n\\ntqdm: For adding progress bars to your loops, which is incredibly useful for tracking long-running training/inference tasks.\\n\\npython-dotenv: For managing environment variables (e.g., API keys for OpenAI, Pinecone) securely.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. Using character text splitter\n",
    "text = documents[0].page_content\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8433a804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character Text Splitter\n",
      "Created 8 chunks\n",
      "\n",
      "First chunk: Of course. Python is the undisputed lingua franca for Generative AI, and its ecosystem of libraries makes it incredibly powerful for building applications like RAG systems, image generators, and more.\n",
      "Here is a breakdown of the essential Python libraries, concepts, and resources for Generative AI, moving from foundational to advanced.\n",
      "The Core Python Stack for Generative AI\n",
      "Your toolkit will primarily consist of these libraries:\n",
      "Core Numerical & Deep Learning Framework:[:100]....\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Character Text Splitter')\n",
    "char_splitter = CharacterTextSplitter(\n",
    "    separator='\\n', #\n",
    "    chunk_size= 500, #Maximum size in character per chunk\n",
    "    chunk_overlap=20, # Overlap between chunks\n",
    "    length_function=len # How to measure chunk size \n",
    ")\n",
    "\n",
    "char_chunks = char_splitter.split_text(text)\n",
    "\n",
    "print(f'Created {len(char_chunks)} chunks')\n",
    "print(f'\\nFirst chunk: {char_chunks[0]}[:100]....\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac47590d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course. Python is the undisputed lingua franca for Generative AI, and its ecosystem of libraries makes it incredibly powerful for building applications like RAG systems, image generators, and more.\n",
      "Here is a breakdown of the essential Python libraries, concepts, and resources for Generative AI, moving from foundational to advanced.\n",
      "The Core Python Stack for Generative AI\n",
      "Your toolkit will primarily consist of these libraries:\n",
      "Core Numerical & Deep Learning Framework: \n",
      "\n",
      "PyTorch (torch): Developed by Meta, it's the most popular framework for cutting-edge AI research, including most new LLMs. Its dynamic computation graph (eager execution) is very intuitive for debugging and experimentation.\n",
      "TensorFlow (tensorflow): Developed by Google, it's a very powerful and production-hardened framework. While its market share in research has been overtaken by PyTorch, it's still widely used, especially with its high-level API Keras. \n",
      "\n",
      "JAX: Gaining rapid traction in research for its incredible speed and composable transformations (gradients, jit, vmap). It's used by Google DeepMind for models like Gemini.\n",
      "Recommendation for Beginners: Start with PyTorch. Most tutorials, research code, and pre-trained models are released in PyTorch first. \n",
      "\n",
      "The Hugging Face Ecosystem (transformers, datasets, accelerate): This is non-negotiable for working with LLMs. It provides a unified and incredibly simple API to thousands of pre-trained models.\n",
      "transformers: The main library for downloading and using pre-trained models (for text, vision, audio) for tasks like text generation, summarization, and classification.\n",
      "datasets: Provides easy access to thousands of datasets for training and evaluation. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(char_chunks[0],'\\n')\n",
    "print(char_chunks[1], '\\n')\n",
    "print(char_chunks[2], '\\n')\n",
    "print(char_chunks[3], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a82d357",
   "metadata": {},
   "source": [
    "#1. Using Recursive character splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59d4b8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Recursive Character Text Splitter\n"
     ]
    }
   ],
   "source": [
    "print('\\n Recursive Character Text Splitter')\n",
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=['\\n\\n', '\\n', ' ', ''],\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124c453b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: 24 chunks\n",
      "\n",
      "First chunk: Of course. Python is the undisputed lingua franca for Generative AI, and its ecosystem of libraries .....\n"
     ]
    }
   ],
   "source": [
    "recursive_chunks = recursive_splitter.split_text(text)\n",
    "print(f'Created: {len(recursive_chunks)} chunks\\n')\n",
    "print(f'First chunk: {recursive_chunks[0][:50]}.....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0cfa3e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course. Python is the undisputed lingua franca for Generative AI, and its ecosystem of libraries makes it incredibly powerful for building applications like RAG systems, image generators, and more.\n",
      "****************************************\n",
      "Here is a breakdown of the essential Python libraries, concepts, and resources for Generative AI, moving from foundational to advanced.\n",
      "****************************************\n",
      "The Core Python Stack for Generative AI\n",
      "Your toolkit will primarily consist of these libraries:\n",
      "\n",
      "Core Numerical & Deep Learning Framework:\n",
      "****************************************\n",
      "PyTorch (torch): Developed by Meta, it's the most popular framework for cutting-edge AI research, including most new LLMs. Its dynamic computation graph (eager execution) is very intuitive for\n"
     ]
    }
   ],
   "source": [
    "print(recursive_chunks[0])\n",
    "print('*' * 40)\n",
    "print(recursive_chunks[1])\n",
    "print('*' * 40)\n",
    "print(recursive_chunks[2])\n",
    "print('*' * 40)\n",
    "print(recursive_chunks[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3cac8d",
   "metadata": {},
   "source": [
    "Token Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bafe2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: 20 chunks\n",
      "\n",
      "First chunk: Of course. Python is the undisputed lingua franca .....\n"
     ]
    }
   ],
   "source": [
    "token_splitter = TokenTextSplitter(\n",
    "    chunk_size=50,\n",
    "    chunk_overlap= 10\n",
    ")\n",
    "\n",
    "token_chunks = token_splitter.split_text(text)\n",
    "print(f'Created: {len(token_chunks)} chunks\\n')\n",
    "print(f'First chunk: {token_chunks[0][:50]}.....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d74bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8dad894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any\n",
    "import pandas as pd\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter, TokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4fb0d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up Completed\n"
     ]
    }
   ],
   "source": [
    "print('Set up Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d702e34a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
