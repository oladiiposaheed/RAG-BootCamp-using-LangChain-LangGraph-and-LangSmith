{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6e95057",
   "metadata": {},
   "source": [
    "### Building RAG System with LangChain and ChromaDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbda4a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\RAG_project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# langchain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "#vectorstore\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader # To load a document from any dir\n",
    "#Embedding\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline # Huggingface model\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chat_models.base import init_chat_model # Initialize llm model\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "#RAG using LCEL\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from dotenv import load_dotenv\n",
    "#import utilities\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e9452d",
   "metadata": {},
   "source": [
    "Create Data (Document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "824a6fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# Define a list of documents, each as a separate string\n",
    "docs = [\n",
    "    '''\n",
    "    Python Programming Language\n",
    "    \n",
    "    ğŸ **Python** is a high-level, interpreted programming language known for its simplicity and readability.  \n",
    "    ğŸ’¡ It supports multiple programming paradigms, including procedural, object-oriented, and functional styles.  \n",
    "    ğŸš€ Widely used in web development, data science, automation, AI, and more.  \n",
    "    ğŸ“š Python has a vast ecosystem of libraries and frameworks like Django, NumPy, and TensorFlow.  \n",
    "    ğŸŒ Its clear syntax and strong community make it ideal for beginners and professionals alike.\n",
    "    ''',\n",
    "\n",
    "    '''\n",
    "    Introduction to Machine Learning\n",
    "    \n",
    "    ğŸ¤– **Machine Learning (ML)** is a branch of artificial intelligence that enables systems to learn from data without being explicitly programmed.  \n",
    "    ğŸ“ˆ It uses algorithms to identify patterns, make predictions, or improve performance over time.  \n",
    "    ğŸ§  ML models are trained on datasets and adjust themselves based on feedback or new inputs.  \n",
    "    ğŸ” Common types include supervised, unsupervised, and reinforcement learning.  \n",
    "    ğŸ’¬ Applications range from speech recognition and spam filtering to fraud detection and self-driving cars.  \n",
    "    ğŸ› ï¸ Tools like Python, TensorFlow, and Scikit-learn are popular in ML development.  \n",
    "    ğŸŒ ML is transforming industries by automating decisions and uncovering insights from big data.\n",
    "    ''',\n",
    "\n",
    "    '''\n",
    "    Django for Backend Development\n",
    "    \n",
    "    ğŸŒ **Django** is a high-level Python web framework that enables rapid development of secure and maintainable websites.  \n",
    "    âš™ï¸ It follows the Model-View-Template (MVT) architectural pattern to separate data, logic, and presentation.  \n",
    "    ğŸš€ Django comes with built-in features like authentication, admin interface, and URL routing.  \n",
    "    ğŸ›¡ï¸ It emphasizes security, helping developers avoid common threats like SQL injection and cross-site scripting.  \n",
    "    ğŸ“¦ With its \"batteries-included\" philosophy, Django provides everything needed to build full-stack web apps.  \n",
    "    ğŸ” It's widely used for content management systems, social networks, and scientific platforms.  \n",
    "    ğŸŒ Django powers popular sites like Instagram, Pinterest, and Mozilla.\n",
    "    ''',\n",
    "\n",
    "    '''\n",
    "    Introduction to Deep Learning\n",
    "    \n",
    "    ğŸ§  **Deep Learning** is a subset of machine learning that uses neural networks with many layers to model complex patterns in data.  \n",
    "    ğŸ”— These layers mimic the human brainâ€™s structure, enabling systems to learn hierarchical representations.  \n",
    "    ğŸ“š It excels at tasks like image recognition, natural language processing, and speech translation.  \n",
    "    ğŸ§ª Deep learning models require large datasets and powerful computing resources to train effectively.  \n",
    "    ğŸ•¸ï¸ Popular architectures include Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs).  \n",
    "    ğŸ› ï¸ Frameworks like TensorFlow and PyTorch are commonly used to build deep learning applications.  \n",
    "    ğŸš€ Deep learning drives innovations in autonomous vehicles, medical diagnostics, and generative AI.\n",
    "    '''\n",
    "]\n",
    "\n",
    "# Verify how many documents are in the list\n",
    "print(len(docs))  # Should print 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edab7565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample documents created in: C:\\Users\\USER\\AppData\\Local\\Temp\\tmp7gffdysx\n",
      "Files created: ['doc_0.txt', 'doc_1.txt', 'doc_2.txt', 'doc_3.txt']\n"
     ]
    }
   ],
   "source": [
    "# Import the tempfile module, which provides functions to create temporary files and directories\n",
    "import tempfile\n",
    "\n",
    "# Import the os module, which provides utilities for file and path operations\n",
    "import os\n",
    "\n",
    "# mkdtemp() creates a temporary directory and returns its path as a string\n",
    "# Unlike mkstemp(), this avoids dealing with file descriptors\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "# Loop through the list of documents 'docs', with both index (i) and content (doc)\n",
    "for i, doc in enumerate(docs):\n",
    "    \n",
    "    # Construct a new file path inside the temporary directory\n",
    "    # Each file will be named \"doc_0.txt\", \"doc_1.txt\", etc.\n",
    "    file_path = os.path.join(temp_dir, f'doc_{i}.txt')\n",
    "    \n",
    "    # Open the file in write mode (\"w\") with UTF-8 encoding to support all Unicode characters\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        \n",
    "        # Write the document content into the file\n",
    "        f.write(doc)\n",
    "\n",
    "# Print the location of the temporary directory where files were created\n",
    "print(f'Sample documents created in: {temp_dir}')\n",
    "print(\"Files created:\", os.listdir(temp_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9421fc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample documents created in: C:\\Users\\USER\\AppData\\Local\\Temp\\tmpfqeojx3i\n"
     ]
    }
   ],
   "source": [
    "# Import the tempfile module, which provides functions to create temporary files and directories\n",
    "import tempfile\n",
    "\n",
    "# Import the os module, which provides utilities for file and path operations\n",
    "import os\n",
    "\n",
    "# Assume docs is defined here\n",
    "# ...\n",
    "\n",
    "# mkdtemp() creates a temporary directory and returns its path as a string\n",
    "# Unlike mkstemp(), this avoids dealing with file descriptors\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "# Loop through the list of documents 'docs', with both index (i) and content (doc)\n",
    "for i, doc in enumerate(docs):\n",
    "    \n",
    "    # Construct a new file path inside the temporary directory (FIXED)\n",
    "    # Each file will be named \"doc_0.txt\", \"doc_1.txt\", etc.\n",
    "    #file_path = os.path.join(temp_dir, f'doc_{i}.txt') # NOW INCLUDES temp_dir\n",
    "    \n",
    "    # Open the file in write mode (\"w\") with UTF-8 encoding to support all Unicode characters (FIXED)\n",
    "    with open(f'doc_{i}.txt', 'w', encoding='utf-8') as f: # NOW USES the full file_path\n",
    "        \n",
    "        # Write the document content into the file\n",
    "        f.write(doc)\n",
    "\n",
    "# Print the location of the temporary directory where files were created\n",
    "print(f'Sample documents created in: {temp_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6135dd",
   "metadata": {},
   "source": [
    "Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "804f4355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 documents\n",
      "\n",
      "First document preview:\n",
      "\n",
      "    Python Programming Language\n",
      "\n",
      "    ğŸ **Python** is a high-level, interpreted programming language known for its simplicity and readability.  \n",
      "    ğŸ’¡ It supports multiple programming paradigms, inclu...\n"
     ]
    }
   ],
   "source": [
    "# Load documents from directory\n",
    "\n",
    "loader = DirectoryLoader( # Initialize a DirectoryLoader object to find and load text files from a specific folder.\n",
    "    'data', # Specify the directory to search within.\n",
    "    glob='*.txt', # Use a glob pattern to only select files ending in '.txt'.\n",
    "    loader_cls=TextLoader, # Define the class to be used for loading each file (TextLoader handles simple text).\n",
    "    loader_kwargs={'encoding': 'utf-8'} # Pass arguments to the TextLoader, ensuring files are read with UTF-8 encoding.\n",
    ")\n",
    "\n",
    "documents = loader.load() # Execute the loader to read all matching files and store their contents as a list of 'documents'.\n",
    "\n",
    "print(f'Loaded {len(documents)} documents')\n",
    "print(f'\\nFirst document preview:') \n",
    "print(documents[0].page_content[:200] + '...') # Print the beginning content (first 200 characters) of the first loaded document for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e499aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='\\n    Python Programming Language\\n\\n    ğŸ **Python** is a high-level, interpreted programming language known for its simplicity and readability.  \\n    ğŸ’¡ It supports multiple programming paradigms, including procedural, object-oriented, and functional styles.  \\n    ğŸš€ Widely used in web development, data science, automation, AI, and more.  \\n    ğŸ“š Python has a vast ecosystem of libraries and frameworks like Django, NumPy, and TensorFlow.  \\n    ğŸŒ Its clear syntax and strong community make it ideal for beginners and professionals alike.\\n    '),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='\\n    Introduction to Machine Learning\\n\\n    ğŸ¤– **Machine Learning (ML)** is a branch of artificial intelligence that enables systems to learn from data without being explicitly programmed.  \\n    ğŸ“ˆ It uses algorithms to identify patterns, make predictions, or improve performance over time.  \\n    ğŸ§  ML models are trained on datasets and adjust themselves based on feedback or new inputs.  \\n    ğŸ” Common types include supervised, unsupervised, and reinforcement learning.  \\n    ğŸ’¬ Applications range from speech recognition and spam filtering to fraud detection and self-driving cars.  \\n    ğŸ› ï¸ Tools like Python, TensorFlow, and Scikit-learn are popular in ML development.  \\n    ğŸŒ ML is transforming industries by automating decisions and uncovering insights from big data.\\n    '),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='\\n    Django for Backend Development\\n\\n    ğŸŒ **Django** is a high-level Python web framework that enables rapid development of secure and maintainable websites.  \\n    âš™ï¸ It follows the Model-View-Template (MVT) architectural pattern to separate data, logic, and presentation.  \\n    ğŸš€ Django comes with built-in features like authentication, admin interface, and URL routing.  \\n    ğŸ›¡ï¸ It emphasizes security, helping developers avoid common threats like SQL injection and cross-site scripting.  \\n    ğŸ“¦ With its \"batteries-included\" philosophy, Django provides everything needed to build full-stack web apps.  \\n    ğŸ” It\\'s widely used for content management systems, social networks, and scientific platforms.  \\n    ğŸŒ Django powers popular sites like Instagram, Pinterest, and Mozilla.\\n    '),\n",
       " Document(metadata={'source': 'data\\\\doc_3.txt'}, page_content='\\n    Introduction to Deep Learning\\n\\n    ğŸ§  **Deep Learning** is a subset of machine learning that uses neural networks with many layers to model complex patterns in data.  \\n    ğŸ”— These layers mimic the human brainâ€™s structure, enabling systems to learn hierarchical representations.  \\n    ğŸ“š It excels at tasks like image recognition, natural language processing, and speech translation.  \\n    ğŸ§ª Deep learning models require large datasets and powerful computing resources to train effectively.  \\n    ğŸ•¸ï¸ Popular architectures include Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs).  \\n    ğŸ› ï¸ Frameworks like TensorFlow and PyTorch are commonly used to build deep learning applications.  \\n    ğŸš€ Deep learning drives innovations in autonomous vehicles, medical diagnostics, and generative AI.\\n    ')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff398cc",
   "metadata": {},
   "source": [
    "Document Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cef7c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RecursiveCharacterTextSplitter instance to break long text into smaller, structured segments for efficient LLM input\n",
    "test_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,              # Limit each chunk to 500 characters\n",
    "    chunk_overlap=50,            # Retain 50 characters of overlap for context continuity\n",
    "    length_function=len,         # Measure chunk size using character count\n",
    "    separators=[' ']  # Use spaces as the main split point; can be expanded to paragraphs, sentences, or characters\n",
    ")\n",
    "\n",
    "#separators=['\\n\\n', '. ', ' ',  ''] # Ordered list of delimiters, split hierarchically: # Split by paragraphs, sentences, words, then characters\n",
    "\n",
    "chunks = test_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e92d68f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 8 chunks from 4 documents\n",
      "\n",
      " Chunk examples\n",
      "Content: Python Programming Language\n",
      "\n",
      "    ğŸ **Python** is a high-level, interpreted programming language known for its simplicity and readability.  \n",
      "    ğŸ’¡ It s...\n",
      "Metadata: {'source': 'data\\\\doc_0.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(f'Created {len(chunks)} chunks from {len(documents)} documents')\n",
    "print(f'\\n Chunk examples')\n",
    "print(f'Content: {chunks[0].page_content[:150]}...')\n",
    "print(f'Metadata: {chunks[0].metadata}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f6e4472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='\\n    Python Programming Language\\n\\n    ğŸ **Python** is a high-level, interpreted programming language known for its simplicity and readability.  \\n    ğŸ’¡ It supports multiple programming paradigms, including procedural, object-oriented, and functional styles.  \\n    ğŸš€ Widely used in web development, data science, automation, AI, and more.  \\n    ğŸ“š Python has a vast ecosystem of libraries and frameworks like Django, NumPy, and TensorFlow.  \\n    ğŸŒ Its clear syntax and strong community make it ideal for beginners and professionals alike.\\n    '),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='\\n    Introduction to Machine Learning\\n\\n    ğŸ¤– **Machine Learning (ML)** is a branch of artificial intelligence that enables systems to learn from data without being explicitly programmed.  \\n    ğŸ“ˆ It uses algorithms to identify patterns, make predictions, or improve performance over time.  \\n    ğŸ§  ML models are trained on datasets and adjust themselves based on feedback or new inputs.  \\n    ğŸ” Common types include supervised, unsupervised, and reinforcement learning.  \\n    ğŸ’¬ Applications range from speech recognition and spam filtering to fraud detection and self-driving cars.  \\n    ğŸ› ï¸ Tools like Python, TensorFlow, and Scikit-learn are popular in ML development.  \\n    ğŸŒ ML is transforming industries by automating decisions and uncovering insights from big data.\\n    '),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='\\n    Django for Backend Development\\n\\n    ğŸŒ **Django** is a high-level Python web framework that enables rapid development of secure and maintainable websites.  \\n    âš™ï¸ It follows the Model-View-Template (MVT) architectural pattern to separate data, logic, and presentation.  \\n    ğŸš€ Django comes with built-in features like authentication, admin interface, and URL routing.  \\n    ğŸ›¡ï¸ It emphasizes security, helping developers avoid common threats like SQL injection and cross-site scripting.  \\n    ğŸ“¦ With its \"batteries-included\" philosophy, Django provides everything needed to build full-stack web apps.  \\n    ğŸ” It\\'s widely used for content management systems, social networks, and scientific platforms.  \\n    ğŸŒ Django powers popular sites like Instagram, Pinterest, and Mozilla.\\n    '),\n",
       " Document(metadata={'source': 'data\\\\doc_3.txt'}, page_content='\\n    Introduction to Deep Learning\\n\\n    ğŸ§  **Deep Learning** is a subset of machine learning that uses neural networks with many layers to model complex patterns in data.  \\n    ğŸ”— These layers mimic the human brainâ€™s structure, enabling systems to learn hierarchical representations.  \\n    ğŸ“š It excels at tasks like image recognition, natural language processing, and speech translation.  \\n    ğŸ§ª Deep learning models require large datasets and powerful computing resources to train effectively.  \\n    ğŸ•¸ï¸ Popular architectures include Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs).  \\n    ğŸ› ï¸ Frameworks like TensorFlow and PyTorch are commonly used to build deep learning applications.  \\n    ğŸš€ Deep learning drives innovations in autonomous vehicles, medical diagnostics, and generative AI.\\n    ')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Documents')\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dcd2a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 is divided into 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Python Programming Language\\n\\n    ğŸ **Python** is a high-level, interpreted programming language known for its simplicity and readability.  \\n    ğŸ’¡ It supports multiple programming paradigms, including procedural, object-oriented, and functional styles.  \\n    ğŸš€ Widely used in web development, data science, automation, AI, and more.  \\n    ğŸ“š Python has a vast ecosystem of libraries and frameworks like Django, NumPy, and TensorFlow.  \\n    ğŸŒ Its clear syntax and strong community make it ideal for'),\n",
       " Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='syntax and strong community make it ideal for beginners and professionals alike.'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Introduction to Machine Learning\\n\\n    ğŸ¤– **Machine Learning (ML)** is a branch of artificial intelligence that enables systems to learn from data without being explicitly programmed.  \\n    ğŸ“ˆ It uses algorithms to identify patterns, make predictions, or improve performance over time.  \\n    ğŸ§  ML models are trained on datasets and adjust themselves based on feedback or new inputs.  \\n    ğŸ” Common types include supervised, unsupervised, and reinforcement learning.  \\n    ğŸ’¬ Applications range from'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='learning.  \\n    ğŸ’¬ Applications range from speech recognition and spam filtering to fraud detection and self-driving cars.  \\n    ğŸ› ï¸ Tools like Python, TensorFlow, and Scikit-learn are popular in ML development.  \\n    ğŸŒ ML is transforming industries by automating decisions and uncovering insights from big data.'),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Django for Backend Development\\n\\n    ğŸŒ **Django** is a high-level Python web framework that enables rapid development of secure and maintainable websites.  \\n    âš™ï¸ It follows the Model-View-Template (MVT) architectural pattern to separate data, logic, and presentation.  \\n    ğŸš€ Django comes with built-in features like authentication, admin interface, and URL routing.  \\n    ğŸ›¡ï¸ It emphasizes security, helping developers avoid common threats like SQL injection and cross-site scripting.  \\n    ğŸ“¦'),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='SQL injection and cross-site scripting.  \\n    ğŸ“¦ With its \"batteries-included\" philosophy, Django provides everything needed to build full-stack web apps.  \\n    ğŸ” It\\'s widely used for content management systems, social networks, and scientific platforms.  \\n    ğŸŒ Django powers popular sites like Instagram, Pinterest, and Mozilla.'),\n",
       " Document(metadata={'source': 'data\\\\doc_3.txt'}, page_content='Introduction to Deep Learning\\n\\n    ğŸ§  **Deep Learning** is a subset of machine learning that uses neural networks with many layers to model complex patterns in data.  \\n    ğŸ”— These layers mimic the human brainâ€™s structure, enabling systems to learn hierarchical representations.  \\n    ğŸ“š It excels at tasks like image recognition, natural language processing, and speech translation.  \\n    ğŸ§ª Deep learning models require large datasets and powerful computing resources to train effectively.'),\n",
       " Document(metadata={'source': 'data\\\\doc_3.txt'}, page_content='computing resources to train effectively.  \\n    ğŸ•¸ï¸ Popular architectures include Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs).  \\n    ğŸ› ï¸ Frameworks like TensorFlow and PyTorch are commonly used to build deep learning applications.  \\n    ğŸš€ Deep learning drives innovations in autonomous vehicles, medical diagnostics, and generative AI.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'{len(documents)} is divided into {len(chunks)}')\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3a7f66",
   "metadata": {},
   "source": [
    "Embedding Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796d3e9e",
   "metadata": {},
   "source": [
    "1. Embedding Model With HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67e14e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. With HuggingFace\n",
    "\n",
    "hf_token = os.getenv('HUGGINGFACEHUB_API_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b4b1882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF embedding length: 384\n",
      "HF embedding preview: [-0.024293294176459312, -0.04733593016862869, 0.02925313450396061, -0.07217934727668762, -0.03708483651280403, -0.0029654146637767553, -0.017474163323640823, 0.06621578335762024, 0.025721492245793343, 0.005787475500255823]\n"
     ]
    }
   ],
   "source": [
    "# Initialize Hugging Face embeddings\n",
    "hf_emddings = HuggingFaceEmbeddings(model='sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Example query\n",
    "text = 'LangChain makes it easy to use LLMs.'\n",
    "vector = hf_emddings.embed_query(text)\n",
    "print(f'HF embedding length: {len(vector)}')\n",
    "print(f'HF embedding preview: {vector[:10]}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47ed9dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.024293294176459312,\n",
       " -0.04733593016862869,\n",
       " 0.02925313450396061,\n",
       " -0.07217934727668762,\n",
       " -0.03708483651280403,\n",
       " -0.0029654146637767553,\n",
       " -0.017474163323640823,\n",
       " 0.06621578335762024,\n",
       " 0.025721492245793343,\n",
       " 0.005787475500255823,\n",
       " 0.027516314759850502,\n",
       " 0.05101742595434189,\n",
       " 0.02604765072464943,\n",
       " 0.023985203355550766,\n",
       " 0.057821813970804214,\n",
       " 0.030977502465248108,\n",
       " 0.06038447842001915,\n",
       " 0.09654975682497025,\n",
       " 0.0828777402639389,\n",
       " -0.08375709503889084,\n",
       " -0.016788316890597343,\n",
       " -0.05233118683099747,\n",
       " 0.03956417366862297,\n",
       " 0.02312644198536873,\n",
       " 0.06321760267019272,\n",
       " -0.03850008174777031,\n",
       " 0.0018039962742477655,\n",
       " 0.07416681200265884,\n",
       " 0.08565447479486465,\n",
       " -0.09831225872039795,\n",
       " 0.017451513558626175,\n",
       " 0.10537837445735931,\n",
       " -0.01619138941168785,\n",
       " -0.017408110201358795,\n",
       " -0.14930865168571472,\n",
       " 0.034462373703718185,\n",
       " 0.003808281384408474,\n",
       " 0.021017681807279587,\n",
       " -0.06894774734973907,\n",
       " -0.035061608999967575,\n",
       " -0.034660983830690384,\n",
       " -0.013271057978272438,\n",
       " 0.05375698208808899,\n",
       " -0.02974868379533291,\n",
       " 0.02492610551416874,\n",
       " -0.014925874769687653,\n",
       " -0.010124459862709045,\n",
       " 0.060388363897800446,\n",
       " -0.07894699275493622,\n",
       " 0.03249075263738632,\n",
       " 0.035701848566532135,\n",
       " -0.09813376516103745,\n",
       " -0.014689836651086807,\n",
       " -0.011493436060845852,\n",
       " -0.05795262008905411,\n",
       " -0.015544221736490726,\n",
       " -0.022120192646980286,\n",
       " 0.04998370632529259,\n",
       " 0.011710765771567822,\n",
       " 0.014387054368853569,\n",
       " -0.014514175243675709,\n",
       " 0.009803993627429008,\n",
       " -0.06359067559242249,\n",
       " 0.0719185471534729,\n",
       " 0.007580937352031469,\n",
       " 0.04497486725449562,\n",
       " 0.04912396892905235,\n",
       " 0.13650910556316376,\n",
       " -0.004059249069541693,\n",
       " 0.0023908328730612993,\n",
       " -0.04413434863090515,\n",
       " -0.09369717538356781,\n",
       " 0.012305797077715397,\n",
       " 0.11148161441087723,\n",
       " -0.08240898698568344,\n",
       " -0.017863566055893898,\n",
       " 0.02903692238032818,\n",
       " -0.059253282845020294,\n",
       " 0.06741241365671158,\n",
       " 0.02553488314151764,\n",
       " -0.0017002368113026023,\n",
       " 0.11448131501674652,\n",
       " -0.01189237181097269,\n",
       " 0.06638406962156296,\n",
       " 0.033229902386665344,\n",
       " -0.0009577277232892811,\n",
       " -0.008154871873557568,\n",
       " 0.00888353306800127,\n",
       " 0.03552025929093361,\n",
       " -0.02106585167348385,\n",
       " 0.09586663544178009,\n",
       " -0.005798318888992071,\n",
       " -0.04265880957245827,\n",
       " -0.0042769392021000385,\n",
       " -0.018251394852995872,\n",
       " -0.0290007796138525,\n",
       " 0.005922089796513319,\n",
       " 0.03909248113632202,\n",
       " -0.05364277586340904,\n",
       " 0.011659706942737103,\n",
       " 0.005692564882338047,\n",
       " 0.0028434612322598696,\n",
       " 0.019386334344744682,\n",
       " -0.05152690410614014,\n",
       " -0.07632052898406982,\n",
       " -0.023075252771377563,\n",
       " 0.014535530470311642,\n",
       " -0.03924214839935303,\n",
       " 0.07241211086511612,\n",
       " -0.05056300386786461,\n",
       " -0.027056090533733368,\n",
       " 0.034390613436698914,\n",
       " -0.0174275953322649,\n",
       " -0.022667063400149345,\n",
       " -0.10221628844738007,\n",
       " -0.04625565558671951,\n",
       " 0.03786022588610649,\n",
       " -0.06047571450471878,\n",
       " 0.05573853477835655,\n",
       " 0.049944229423999786,\n",
       " -0.06938163936138153,\n",
       " -0.0400671660900116,\n",
       " -0.04289737716317177,\n",
       " -0.0302888210862875,\n",
       " 0.01305350847542286,\n",
       " 0.017394844442605972,\n",
       " 0.010248512029647827,\n",
       " -1.2697945280261669e-33,\n",
       " 0.06396373361349106,\n",
       " 0.04481833428144455,\n",
       " -0.022189505398273468,\n",
       " 0.016253594309091568,\n",
       " 0.08673705905675888,\n",
       " -0.05725077912211418,\n",
       " 0.046033523976802826,\n",
       " 0.006191228050738573,\n",
       " -0.08222925662994385,\n",
       " -0.045712944120168686,\n",
       " -0.02932349406182766,\n",
       " -0.013093046844005585,\n",
       " -0.06854606419801712,\n",
       " 0.014095981605350971,\n",
       " 0.054704390466213226,\n",
       " -0.06293173134326935,\n",
       " 0.003936076071113348,\n",
       " -0.011271849274635315,\n",
       " 0.021491942927241325,\n",
       " -0.040112532675266266,\n",
       " -0.005224376451224089,\n",
       " 0.018139399588108063,\n",
       " 0.08828216791152954,\n",
       " -0.0526183657348156,\n",
       " 0.07819519191980362,\n",
       " 0.059732381254434586,\n",
       " 0.14189018309116364,\n",
       " -0.013872122392058372,\n",
       " 0.09750868380069733,\n",
       " 0.021959412842988968,\n",
       " -0.011856996454298496,\n",
       " -0.053804460912942886,\n",
       " -0.035767313092947006,\n",
       " 0.01495630107820034,\n",
       " -0.009230815805494785,\n",
       " 0.06975405663251877,\n",
       " -0.12216626852750778,\n",
       " -0.03523329645395279,\n",
       " 0.06010757386684418,\n",
       " -0.060838066041469574,\n",
       " 0.021467609331011772,\n",
       " 0.048675503581762314,\n",
       " 0.01690393127501011,\n",
       " -0.026969565078616142,\n",
       " -0.02816217765212059,\n",
       " 0.030869169160723686,\n",
       " -0.024480042979121208,\n",
       " 0.012768648564815521,\n",
       " 0.03260205313563347,\n",
       " 0.0032919689547270536,\n",
       " 0.05564548447728157,\n",
       " 0.01125443447381258,\n",
       " -0.1262795478105545,\n",
       " 0.037206318229436874,\n",
       " -0.004266127943992615,\n",
       " 0.02481400966644287,\n",
       " 0.008428225293755531,\n",
       " -0.042933911085128784,\n",
       " -0.045967716723680496,\n",
       " 0.06085766851902008,\n",
       " -0.07689572870731354,\n",
       " 0.05108245462179184,\n",
       " 0.01379952859133482,\n",
       " 0.03247522562742233,\n",
       " 0.08030497282743454,\n",
       " 0.010733982548117638,\n",
       " -0.08187149465084076,\n",
       " -0.022189654409885406,\n",
       " -0.011426487937569618,\n",
       " -0.07870007306337357,\n",
       " -0.017857326194643974,\n",
       " -0.03843032196164131,\n",
       " 0.01435548160225153,\n",
       " 0.05744871869683266,\n",
       " -0.046606726944446564,\n",
       " -0.014278278686106205,\n",
       " 0.02541928179562092,\n",
       " -0.03894084319472313,\n",
       " 0.05865384265780449,\n",
       " -0.012788556516170502,\n",
       " 0.006864013150334358,\n",
       " -0.01730605959892273,\n",
       " -0.04567503556609154,\n",
       " 0.05656401440501213,\n",
       " 0.00828399509191513,\n",
       " -0.018674740567803383,\n",
       " -0.0011777161853387952,\n",
       " -0.07384324073791504,\n",
       " 0.024751173332333565,\n",
       " 0.0509859062731266,\n",
       " -0.011251899413764477,\n",
       " -0.06480730324983597,\n",
       " 0.0625445768237114,\n",
       " 0.09146986901760101,\n",
       " -0.07641798257827759,\n",
       " 2.268251348090956e-33,\n",
       " -0.07504027336835861,\n",
       " -0.09051781892776489,\n",
       " 0.05395173653960228,\n",
       " 0.14746615290641785,\n",
       " -0.013666103594005108,\n",
       " -0.012313020415604115,\n",
       " 0.03152458742260933,\n",
       " 0.07543817907571793,\n",
       " -0.005969640798866749,\n",
       " 0.019308341667056084,\n",
       " -0.0455586314201355,\n",
       " 0.006966453976929188,\n",
       " 0.00041176192462444305,\n",
       " 0.025916781276464462,\n",
       " 0.05013164132833481,\n",
       " -0.028475213795900345,\n",
       " 0.020238695666193962,\n",
       " -0.011265098117291927,\n",
       " 0.03897377476096153,\n",
       " 0.007914921268820763,\n",
       " -0.03355912119150162,\n",
       " 0.10848364233970642,\n",
       " -0.027477458119392395,\n",
       " 0.031073948368430138,\n",
       " -0.03176124766469002,\n",
       " 0.01391791831701994,\n",
       " -0.047801509499549866,\n",
       " 0.009524996392428875,\n",
       " -0.035218313336372375,\n",
       " 0.0730970948934555,\n",
       " 0.045576613396406174,\n",
       " -0.07325037568807602,\n",
       " -0.03275230899453163,\n",
       " -0.056813862174749374,\n",
       " -0.08641896396875381,\n",
       " 0.008730011060833931,\n",
       " 0.02781600132584572,\n",
       " 0.07937607169151306,\n",
       " -0.016271628439426422,\n",
       " -0.03281811252236366,\n",
       " 0.04559589549899101,\n",
       " -0.022623660042881966,\n",
       " -0.015562508255243301,\n",
       " 0.033981408923864365,\n",
       " -0.024791713804006577,\n",
       " 0.003420695662498474,\n",
       " -0.0772603303194046,\n",
       " -0.028805214911699295,\n",
       " 0.0465318039059639,\n",
       " -0.02700660564005375,\n",
       " 0.060848671942949295,\n",
       " -0.08584676682949066,\n",
       " 0.024150870740413666,\n",
       " -0.08780694007873535,\n",
       " -0.0577847920358181,\n",
       " -0.03173411265015602,\n",
       " 0.03996709734201431,\n",
       " -0.06513015925884247,\n",
       " -0.05215667560696602,\n",
       " -0.05093145743012428,\n",
       " -0.034825436770915985,\n",
       " -0.032219208776950836,\n",
       " -0.0017611542716622353,\n",
       " -0.10421161353588104,\n",
       " 0.03580758720636368,\n",
       " 0.027271736413240433,\n",
       " -0.023288581520318985,\n",
       " 0.04688940569758415,\n",
       " -0.041423432528972626,\n",
       " -0.06103095784783363,\n",
       " 0.151713028550148,\n",
       " 0.029219742864370346,\n",
       " -0.018603216856718063,\n",
       " 0.017086917534470558,\n",
       " 0.005861133802682161,\n",
       " -0.050256434828042984,\n",
       " -0.014758926816284657,\n",
       " -0.060253918170928955,\n",
       " -0.03002973459661007,\n",
       " -0.0678492859005928,\n",
       " 0.05309389531612396,\n",
       " -0.002938153687864542,\n",
       " -0.03161781281232834,\n",
       " 0.028369275853037834,\n",
       " 0.0040069506503641605,\n",
       " 0.0451507493853569,\n",
       " 0.039221279323101044,\n",
       " 0.020657118409872055,\n",
       " 0.004553834442049265,\n",
       " 0.029047830030322075,\n",
       " -0.008228886872529984,\n",
       " 0.11670435965061188,\n",
       " 0.026769161224365234,\n",
       " 0.06532274931669235,\n",
       " 0.038201089948415756,\n",
       " -1.642412073010746e-08,\n",
       " -0.010812381282448769,\n",
       " -0.15328332781791687,\n",
       " 0.01104006264358759,\n",
       " -0.009593024849891663,\n",
       " -0.10219140350818634,\n",
       " -0.05381647124886513,\n",
       " 0.047353699803352356,\n",
       " 0.07332728803157806,\n",
       " 0.009385047480463982,\n",
       " -0.010333661921322346,\n",
       " 0.04059334844350815,\n",
       " 0.02226000837981701,\n",
       " -0.10712882876396179,\n",
       " 0.04214945435523987,\n",
       " 0.04137294739484787,\n",
       " 0.014789975248277187,\n",
       " 0.06297989934682846,\n",
       " 0.12680615484714508,\n",
       " -0.10355264693498611,\n",
       " -0.0017305532237514853,\n",
       " -0.02763400413095951,\n",
       " 0.08718463778495789,\n",
       " 0.07737373560667038,\n",
       " 0.0009111216641031206,\n",
       " 0.04347572103142738,\n",
       " -0.02270425483584404,\n",
       " 0.029357081279158592,\n",
       " 0.09273312985897064,\n",
       " 0.0708029568195343,\n",
       " -0.04312235489487648,\n",
       " -0.023334559053182602,\n",
       " -0.0005554755916818976,\n",
       " -0.02417202852666378,\n",
       " 0.08015003055334091,\n",
       " -0.02520429529249668,\n",
       " 0.02590087056159973,\n",
       " -0.08918316662311554,\n",
       " -0.03874018043279648,\n",
       " 0.05765552446246147,\n",
       " 0.016779402270913124,\n",
       " 0.04155886918306351,\n",
       " -0.014417247846722603,\n",
       " 0.0015523028559982777,\n",
       " 0.07674966007471085,\n",
       " -0.07775355875492096,\n",
       " -0.07468356192111969,\n",
       " -0.016010260209441185,\n",
       " -0.05034889653325081,\n",
       " 0.016508542001247406,\n",
       " 0.007917867973446846,\n",
       " 0.013174246996641159,\n",
       " -0.03138604760169983,\n",
       " 0.036787405610084534,\n",
       " -0.021111907437443733,\n",
       " 0.008775076828897,\n",
       " 0.009010575711727142,\n",
       " -0.0037467116490006447,\n",
       " -0.0032556280493736267,\n",
       " 0.07398958504199982,\n",
       " 0.025576474145054817,\n",
       " 0.03471945598721504,\n",
       " -0.0008353337179869413,\n",
       " 0.026630625128746033,\n",
       " 0.04512910544872284]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70de62d2",
   "metadata": {},
   "source": [
    "Initialize ChromaDB Vector Store, then insert the chunks in vector format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24504cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created with 32 vectors\n",
      "Persisted to: ./chroma_db\n"
     ]
    }
   ],
   "source": [
    "# Create Chromadb vector store\n",
    "\n",
    "persist_directory = './chroma_db' # Path/directory where the vector store data will be saved\n",
    "\n",
    "# Instantiate Chroma from documents using the specified embedding model(HuggingFace)\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks, # Documents/chunks to be embedded\n",
    "    embedding=HuggingFaceEmbeddings(), # Model to create embeddings (HuggingFace)\n",
    "    persist_directory=persist_directory, # Save the store to this directory\n",
    "    collection_name='rag_collection' # Name for the collection in Chroma\n",
    ")\n",
    "\n",
    "print(f'Vector store created with {vectorstore._collection.count()} vectors')\n",
    "print(f'Persisted to: {persist_directory}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f65f7e",
   "metadata": {},
   "source": [
    "2. Embedding Model with OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bb8add9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2713bb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x000001C82B1F7B60>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x000001C82CFD8590>, model='text-embedding-ada-002', dimensions=None, deployment='text-embedding-ada-002', openai_api_version=None, openai_api_base=None, openai_api_type=None, openai_proxy=None, embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = 'What is machine learning?'\n",
    "embeddings = OpenAIEmbeddings()\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f41a7fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector = embeddings.embed_query(sample_text)\n",
    "# vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27391715",
   "metadata": {},
   "source": [
    "Test Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97d68303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Introduction to Machine Learning\\n\\n    ğŸ¤– **Machine Learning (ML)** is a branch of artificial intelligence that enables systems to learn from data without being explicitly programmed.  \\n    ğŸ“ˆ It uses algorithms to identify patterns, make predictions, or improve performance over time.  \\n    ğŸ§  ML models are trained on datasets and adjust themselves based on feedback or new inputs.  \\n    ğŸ” Common types include supervised, unsupervised, and reinforcement learning.  \\n    ğŸ’¬ Applications range from'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Introduction to Machine Learning\\n\\n    ğŸ¤– **Machine Learning (ML)** is a branch of artificial intelligence that enables systems to learn from data without being explicitly programmed.  \\n    ğŸ“ˆ It uses algorithms to identify patterns, make predictions, or improve performance over time.  \\n    ğŸ§  ML models are trained on datasets and adjust themselves based on feedback or new inputs.  \\n    ğŸ” Common types include supervised, unsupervised, and reinforcement learning.  \\n    ğŸ’¬ Applications range from')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'List the type of machine learning'\n",
    "\n",
    "similar_docs = vectorstore.similarity_search(query, k=2)\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3439a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Python Programming Language\\n\\n    ğŸ **Python** is a high-level, interpreted programming language known for its simplicity and readability.  \\n    ğŸ’¡ It supports multiple programming paradigms, including procedural, object-oriented, and functional styles.  \\n    ğŸš€ Widely used in web development, data science, automation, AI, and more.  \\n    ğŸ“š Python has a vast ecosystem of libraries and frameworks like Django, NumPy, and TensorFlow.  \\n    ğŸŒ Its clear syntax and strong community make it ideal for'),\n",
       " Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Python Programming Language\\n\\n    ğŸ **Python** is a high-level, interpreted programming language known for its simplicity and readability.  \\n    ğŸ’¡ It supports multiple programming paradigms, including procedural, object-oriented, and functional styles.  \\n    ğŸš€ Widely used in web development, data science, automation, AI, and more.  \\n    ğŸ“š Python has a vast ecosystem of libraries and frameworks like Django, NumPy, and TensorFlow.  \\n    ğŸŒ Its clear syntax and strong community make it ideal for'),\n",
       " Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Python Programming Language\\n\\n    ğŸ **Python** is a high-level, interpreted programming language known for its simplicity and readability.  \\n    ğŸ’¡ It supports multiple programming paradigms, including procedural, object-oriented, and functional styles.  \\n    ğŸš€ Widely used in web development, data science, automation, AI, and more.  \\n    ğŸ“š Python has a vast ecosystem of libraries and frameworks like Django, NumPy, and TensorFlow.  \\n    ğŸŒ Its clear syntax and strong community make it ideal for')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query1 = 'what is a python?'\n",
    "\n",
    "similar_docs_1 = vectorstore.similarity_search(query1, k=3)\n",
    "similar_docs_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d704eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2e6ab9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: List the type of machine learning\n",
      "\n",
      " 2 similar chunks:\n",
      "\n",
      "********** chunk 1 *************\n",
      "Introduction to Machine Learning\n",
      "\n",
      "    ğŸ¤– **Machine Learning (ML)** is a branch of artificial intelligence that enables systems to learn from data without being explicitly programmed.  \n",
      "    ğŸ“ˆ It uses algorithms to identify patterns, make predictions, or improve performance over time.  \n",
      "    ğŸ§  ML models...\n",
      "Source: data\\doc_1.txt\n",
      "\n",
      "********** chunk 2 *************\n",
      "Introduction to Machine Learning\n",
      "\n",
      "    ğŸ¤– **Machine Learning (ML)** is a branch of artificial intelligence that enables systems to learn from data without being explicitly programmed.  \n",
      "    ğŸ“ˆ It uses algorithms to identify patterns, make predictions, or improve performance over time.  \n",
      "    ğŸ§  ML models...\n",
      "Source: data\\doc_1.txt\n"
     ]
    }
   ],
   "source": [
    "print(f'Query: {query}')\n",
    "print(f'\\n {len(similar_docs)} similar chunks:')\n",
    "\n",
    "for i, doc in enumerate(similar_docs):\n",
    "    print(f'\\n********** chunk {i+1} *************')\n",
    "    print(doc.page_content[:300] + '...')\n",
    "    print(f'Source: {doc.metadata.get('source', 'Unknown')}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98d1ad22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Python Programming Language\\n\\n    ğŸ **Python** is a high-level, interpreted programming language known for its simplicity and readability.  \\n    ğŸ’¡ It supports multiple programming paradigms, including procedural, object-oriented, and functional styles.  \\n    ğŸš€ Widely used in web development, data science, automation, AI, and more.  \\n    ğŸ“š Python has a vast ecosystem of libraries and frameworks like Django, NumPy, and TensorFlow.  \\n    ğŸŒ Its clear syntax and strong community make it ideal for'),\n",
       " Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Python Programming Language\\n\\n    ğŸ **Python** is a high-level, interpreted programming language known for its simplicity and readability.  \\n    ğŸ’¡ It supports multiple programming paradigms, including procedural, object-oriented, and functional styles.  \\n    ğŸš€ Widely used in web development, data science, automation, AI, and more.  \\n    ğŸ“š Python has a vast ecosystem of libraries and frameworks like Django, NumPy, and TensorFlow.  \\n    ğŸŒ Its clear syntax and strong community make it ideal for'),\n",
       " Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Python Programming Language\\n\\n    ğŸ **Python** is a high-level, interpreted programming language known for its simplicity and readability.  \\n    ğŸ’¡ It supports multiple programming paradigms, including procedural, object-oriented, and functional styles.  \\n    ğŸš€ Widely used in web development, data science, automation, AI, and more.  \\n    ğŸ“š Python has a vast ecosystem of libraries and frameworks like Django, NumPy, and TensorFlow.  \\n    ğŸŒ Its clear syntax and strong community make it ideal for')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query1 = 'what is a python?'\n",
    "\n",
    "similar_docs_1 = vectorstore.similarity_search(query1, k=3)\n",
    "similar_docs_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3aaced0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: what is a python?\n",
      "\n",
      " 3 similar chunks:\n",
      "\n",
      "********** chunk 1 *************\n",
      "Python Programming Language\n",
      "\n",
      "    ğŸ **Python** is a high-level, interpreted programming language known for its simplicity and readability.  \n",
      "    ğŸ’¡ It supports multiple programming paradigms, including procedural, object-oriented, and functional styles.  \n",
      "    ğŸš€ Widely used in web development, data sci...\n",
      "Source: data\\doc_0.txt\n",
      "\n",
      "********** chunk 2 *************\n",
      "Python Programming Language\n",
      "\n",
      "    ğŸ **Python** is a high-level, interpreted programming language known for its simplicity and readability.  \n",
      "    ğŸ’¡ It supports multiple programming paradigms, including procedural, object-oriented, and functional styles.  \n",
      "    ğŸš€ Widely used in web development, data sci...\n",
      "Source: data\\doc_0.txt\n",
      "\n",
      "********** chunk 3 *************\n",
      "Python Programming Language\n",
      "\n",
      "    ğŸ **Python** is a high-level, interpreted programming language known for its simplicity and readability.  \n",
      "    ğŸ’¡ It supports multiple programming paradigms, including procedural, object-oriented, and functional styles.  \n",
      "    ğŸš€ Widely used in web development, data sci...\n",
      "Source: data\\doc_0.txt\n"
     ]
    }
   ],
   "source": [
    "print(f'Query: {query1}')\n",
    "print(f'\\n {len(similar_docs_1)} similar chunks:')\n",
    "\n",
    "for i, doc in enumerate(similar_docs_1):\n",
    "    print(f'\\n********** chunk {i+1} *************')\n",
    "    print(doc.page_content[:300] + '...')\n",
    "    print(f'Source: {doc.metadata.get('source', 'Unknown')}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaba0d25",
   "metadata": {},
   "source": [
    "Similarity Search with Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3062c71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Introduction to Machine Learning\\n\\n    ğŸ¤– **Machine Learning (ML)** is a branch of artificial intelligence that enables systems to learn from data without being explicitly programmed.  \\n    ğŸ“ˆ It uses algorithms to identify patterns, make predictions, or improve performance over time.  \\n    ğŸ§  ML models are trained on datasets and adjust themselves based on feedback or new inputs.  \\n    ğŸ” Common types include supervised, unsupervised, and reinforcement learning.  \\n    ğŸ’¬ Applications range from'),\n",
       "  0.5205760598182678),\n",
       " (Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Introduction to Machine Learning\\n\\n    ğŸ¤– **Machine Learning (ML)** is a branch of artificial intelligence that enables systems to learn from data without being explicitly programmed.  \\n    ğŸ“ˆ It uses algorithms to identify patterns, make predictions, or improve performance over time.  \\n    ğŸ§  ML models are trained on datasets and adjust themselves based on feedback or new inputs.  \\n    ğŸ” Common types include supervised, unsupervised, and reinforcement learning.  \\n    ğŸ’¬ Applications range from'),\n",
       "  0.5205760598182678),\n",
       " (Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Introduction to Machine Learning\\n\\n    ğŸ¤– **Machine Learning (ML)** is a branch of artificial intelligence that enables systems to learn from data without being explicitly programmed.  \\n    ğŸ“ˆ It uses algorithms to identify patterns, make predictions, or improve performance over time.  \\n    ğŸ§  ML models are trained on datasets and adjust themselves based on feedback or new inputs.  \\n    ğŸ” Common types include supervised, unsupervised, and reinforcement learning.  \\n    ğŸ’¬ Applications range from'),\n",
       "  0.5205760598182678)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score1 = vectorstore.similarity_search_with_score(query, k=3)\n",
    "similarity_score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03530475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Python Programming Language\\n\\n    ğŸ **Python** is a high-level, interpreted programming language known for its simplicity and readability.  \\n    ğŸ’¡ It supports multiple programming paradigms, including procedural, object-oriented, and functional styles.  \\n    ğŸš€ Widely used in web development, data science, automation, AI, and more.  \\n    ğŸ“š Python has a vast ecosystem of libraries and frameworks like Django, NumPy, and TensorFlow.  \\n    ğŸŒ Its clear syntax and strong community make it ideal for'),\n",
       "  0.8915737867355347),\n",
       " (Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Python Programming Language\\n\\n    ğŸ **Python** is a high-level, interpreted programming language known for its simplicity and readability.  \\n    ğŸ’¡ It supports multiple programming paradigms, including procedural, object-oriented, and functional styles.  \\n    ğŸš€ Widely used in web development, data science, automation, AI, and more.  \\n    ğŸ“š Python has a vast ecosystem of libraries and frameworks like Django, NumPy, and TensorFlow.  \\n    ğŸŒ Its clear syntax and strong community make it ideal for'),\n",
       "  0.8915737867355347),\n",
       " (Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Python Programming Language\\n\\n    ğŸ **Python** is a high-level, interpreted programming language known for its simplicity and readability.  \\n    ğŸ’¡ It supports multiple programming paradigms, including procedural, object-oriented, and functional styles.  \\n    ğŸš€ Widely used in web development, data science, automation, AI, and more.  \\n    ğŸ“š Python has a vast ecosystem of libraries and frameworks like Django, NumPy, and TensorFlow.  \\n    ğŸŒ Its clear syntax and strong community make it ideal for'),\n",
       "  0.8915737867355347)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score2 = vectorstore.similarity_search_with_score(query1, k=3)\n",
    "similarity_score2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c013cf40",
   "metadata": {},
   "source": [
    "Initialize LLM(huggingFace), RAG Chain, Prompt Template, Query the RAG System "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7eba6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(\n",
    "#     model_name='gpt-3.5-turbo',\n",
    "#     temperature=0.2,\n",
    "#     max_tokens=500\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe1ba701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'google/flan-t5-base'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "llm = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "qa_pipeline = pipeline(\n",
    "    'text2text-generation',\n",
    "    model=llm,\n",
    "    tokenizer=tokenizer,\n",
    "    temperature=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2ea2fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nairobi\n"
     ]
    }
   ],
   "source": [
    "question = 'Question: What is the capital of Nigeria? Answer:'\n",
    "response = qa_pipeline(question, max_new_tokens=100)\n",
    "print(response[0]['generated_text'])\n",
    "#response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93be4524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001C82CFDBCB0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001C82D0F8440>, model_name='llama-3.2-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GROQ_API_KEY = os.getenv('GROQ_API_KEY')\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm = init_chat_model('groq:llama-3.2-70b-versatile', api_key=groq_api_key)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ae9d5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm.invoke('What is MAchine learning?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962eca79",
   "metadata": {},
   "source": [
    "Modern RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14273b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001C828E42CF0>, search_kwargs={'k': 3})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert vector store to retriever\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={'k': 3} # Retrieve top 3 relevant chunks\n",
    ")\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84a0f55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prompt template\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a helpful AI assistant.\n",
    "Respond clearly, politely, and concisely, using simple examples when needed.\n",
    "Limit answers to a maximum of four sentences.\n",
    "Always incorporate the provided context: {context}\n",
    "\n",
    "Context: {context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_prompt),\n",
    "    ('human', '{input}')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0110124f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nYou are a helpful AI assistant.\\nRespond clearly, politely, and concisely, using simple examples when needed.\\nLimit answers to a maximum of four sentences.\\nAlways incorporate the provided context: {context}\\n\\nContext: {context}\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d8b3657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nYou are a helpful AI assistant.\\nRespond clearly, politely, and concisely, using simple examples when needed.\\nLimit answers to a maximum of four sentences.\\nAlways incorporate the provided context: {context}\\n\\nContext: {context}\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001C82CFDBCB0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001C82D0F8440>, model_name='llama-3.2-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create document chain\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da526019",
   "metadata": {},
   "source": [
    "##### document_chain = create_stuff_documents_chain(llm, prompt) performs the following key steps:\n",
    "\n",
    "Creates a Chain: It constructs a specific type of LangChain sequence.\n",
    "\n",
    "The \"Stuff\" Strategy: It uses the stuff method, which is the simplest way to get data into a model. It takes all the documents provided, joins them into a single string, and \"stuffs\" that entire string into the context window of the Large Language Model (llm) along with the user's question, according to the structure defined by the prompt.\n",
    "\n",
    "Takes Inputs:\n",
    "\n",
    "llm: The initialized Language Model (e.g., GPT-4, Llama 3) that will process the document content.\n",
    "\n",
    "prompt: A custom or standard ChatPromptTemplate that defines how the model should treat the stuffed documents (e.g., \"Use the following context to answer the question...\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c9f53cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001C828E42CF0>, search_kwargs={'k': 3}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nYou are a helpful AI assistant.\\nRespond clearly, politely, and concisely, using simple examples when needed.\\nLimit answers to a maximum of four sentences.\\nAlways incorporate the provided context: {context}\\n\\nContext: {context}\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "            | ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001C82CFDBCB0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001C82D0F8440>, model_name='llama-3.2-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the final RAG Chain\n",
    "\n",
    "rag_chain = create_retrieval_chain(\n",
    "    retriever,\n",
    "    document_chain\n",
    ")\n",
    "\n",
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "818bcefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#response = rag_chain.invoke({'input': 'What is a Deep learning'})\n",
    "#response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0eadb560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'nairobi'}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fc4e08",
   "metadata": {},
   "source": [
    "Create RAG Chain Using LCEL(LangChain Expression Language) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "059847e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"\\n    Use the following context to answer the question.\\n    If you don't know the answer to the question, say you have no idea.\\n    Provide specific details from the context to support your answer.\\n\\n    Context:\\n    {context}\\n\\n    Question: {question}\\n\\n    Answer:\\n    \"), additional_kwargs={})])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a custom prompt\n",
    "custom_prompt = ChatPromptTemplate.from_template(\n",
    "    '''\n",
    "    Use the following context to answer the question.\n",
    "    If you don't know the answer to the question, say you have no idea.\n",
    "    Provide specific details from the context to support your answer.\n",
    "    \n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Answer:\n",
    "    '''\n",
    ")\n",
    "custom_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b807ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the output documents for the prompt\n",
    "def format_docs(docs):\n",
    "    \n",
    "    format_docs = '\\n\\n'.join(doc.page_content for doc in docs)\n",
    "    return format_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e816d041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001C828E42CF0>, search_kwargs={'k': 3})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ebf411b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001C828E42CF0>, search_kwargs={'k': 3})\n",
       "           | RunnableLambda(format_docs),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"\\n    Use the following context to answer the question.\\n    If you don't know the answer to the question, say you have no idea.\\n    Provide specific details from the context to support your answer.\\n\\n    Context:\\n    {context}\\n\\n    Question: {question}\\n\\n    Answer:\\n    \"), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001C82CFDBCB0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001C82D0F8440>, model_name='llama-3.2-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build chain using LCEL\n",
    "rag_chain_lcel = (\n",
    "    {\n",
    "        'context': retriever | format_docs,\n",
    "        'question': RunnablePassthrough()\n",
    "    }\n",
    "    | custom_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_lcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e8ce1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'nairobi'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#response = rag_chain_lcel.invoke('What Django?')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "140e6e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retriever.get_relevant_documents('What is machine learning?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1c9fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17439717",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42c62085",
   "metadata": {},
   "source": [
    "Advanced RAG Technique - Conversational Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19ee8294",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97cc80b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt = \"\"\"  # Define the system prompt as a multi-line string\n",
    "You are given a chat history between a user and an AI assistant, along with the latest user question.  # Explain input context\n",
    "The latest question may reference prior turns or omit details already discussed, so review the history carefully.  # Note possible dependencies on chat history\n",
    "Rewrite the question so it is fully self-contained, clear, and unambiguous while preserving the userâ€™s intent and tone.  # Instruction to rewrite the question\n",
    "\"\"\"  # End of system prompt definition\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages([  # Create a ChatPromptTemplate using messages\n",
    "    ('system', contextualize_q_system_prompt),  # Add the system role with the defined system prompt\n",
    "    MessagesPlaceholder('chat_history'),  # Insert a placeholder for the chat history\n",
    "    ('human', '{input}'),  # Add the human role with the latest user input\n",
    "])  # End of ChatPromptTemplate definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "12b76c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
       "| VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001C828E42CF0>, search_kwargs={'k': 3}))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001C80A087880>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='  # Define the system prompt as a multi-line string\\nYou are given a chat history between a user and an AI assistant, along with the latest user question.  # Explain input context\\nThe latest question may reference prior turns or omit details already discussed, so review the history carefully.  # Note possible dependencies on chat history\\nRewrite the question so it is fully self-contained, clear, and unambiguous while preserving the userâ€™s intent and tone.  # Instruction to rewrite the question\\n'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001C82CFDBCB0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001C82D0F8440>, model_name='llama-3.2-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()\n",
       "| VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001C828E42CF0>, search_kwargs={'k': 3})), kwargs={}, config={'run_name': 'chat_retriever_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create history aware retriever\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm,  # Use the initialized language model\n",
    "    retriever, # the existing retriever created from the vector store\n",
    "    contextualize_q_prompt # the custom prompt defined above\n",
    ")\n",
    "history_aware_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f742c383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new document chain that includes chat history\n",
    "qa_system_prompt = \"\"\"\n",
    "You are a helpful AI assistant.\n",
    "When answering questions, always refer to the provided context from previous conversations.\n",
    "Limit answers to a maximum of four sentences.\n",
    "\n",
    "Context: {context}\n",
    "\"\"\"\n",
    "\n",
    "# Create the QA prompt template using chat history\n",
    "qa_prompt = ChatPromptTemplate.from_messages([ # Create a ChatPromptTemplate using messages  \n",
    "    ('system', qa_system_prompt), # Add the system role with the defined system prompt to include chat history\n",
    "    MessagesPlaceholder('chat_history'), # Insert a placeholder for the chat history to maintain context i.e. previous Q&A pairs\n",
    "    ('human', '{input}'), # Add the human role with the latest user input\n",
    "])\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
